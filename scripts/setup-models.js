#!/usr/bin/env node

// scripts/setup-models.js
import { spawn } from 'child_process';
import axios from 'axios';
import fs from 'fs/promises';
import path from 'path';
import chalk from 'chalk';
import { fileURLToPath } from 'url';

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

class ModelSetup {
  constructor() {
    this.ollamaEndpoint = 'http://localhost:11434';
    this.models = [
      {
        name: 'llama3.2:3b',
        role: 'router',
        description: 'ë¹ ë¥¸ ì˜ë„ íŒŒì•… ë° ë¼ìš°íŒ… ê²°ì •',
        estimatedSize: '~2GB',
        memoryUsage: '~6GB',
        priority: 1
      },
      {
        name: 'qwen2.5:14b',
        role: 'processor',
        description: 'ë³µì¡í•œ ì½”ë“œ ìƒì„± ë° ë¶„ì„ ì‘ì—…',
        estimatedSize: '~8GB',
        memoryUsage: '~28GB',
        priority: 2
      }
    ];
    this.installedModels = [];
    this.failedModels = [];
  }

  async run() {
    try {
      console.log(chalk.cyan('ğŸ¤– ML MCP ëª¨ë¸ ìë™ ì„¤ì¹˜ ì‹œì‘'));
      console.log(chalk.gray('=' * 50));

      // 1. ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­ í™•ì¸
      await this.checkSystemRequirements();

      // 2. Ollama ì„œë¹„ìŠ¤ í™•ì¸
      await this.checkOllamaService();

      // 3. í˜„ì¬ ì„¤ì¹˜ëœ ëª¨ë¸ í™•ì¸
      await this.checkExistingModels();

      // 4. ëª¨ë¸ ì„¤ì¹˜
      await this.installModels();

      // 5. ì„¤ì¹˜ ì™„ë£Œ í›„ í…ŒìŠ¤íŠ¸
      await this.testInstalledModels();

      // 6. ì„¤ì • íŒŒì¼ ìƒì„±/ì—…ë°ì´íŠ¸
      await this.updateConfigFiles();

      // 7. ì™„ë£Œ ë©”ì‹œì§€
      this.showCompletionMessage();

    } catch (error) {
      console.error(chalk.red('âŒ ëª¨ë¸ ì„¤ì¹˜ ì‹¤íŒ¨:'), error.message);
      process.exit(1);
    }
  }

  async checkSystemRequirements() {
    console.log(chalk.yellow('ğŸ“‹ ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­ í™•ì¸ ì¤‘...'));

    // ë””ìŠ¤í¬ ê³µê°„ í™•ì¸
    try {
      const stats = await fs.stat('./');
      console.log(chalk.green('âœ… ë””ìŠ¤í¬ ì ‘ê·¼ ê°€ëŠ¥'));
    } catch (error) {
      throw new Error('ë””ìŠ¤í¬ ì ‘ê·¼ ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤.');
    }

    // ë©”ëª¨ë¦¬ í™•ì¸
    const totalMemory = process.memoryUsage().heapTotal;
    const totalMemoryGB = Math.round(totalMemory / 1024 / 1024 / 1024);
    
    console.log(chalk.blue(`ğŸ’¾ ì‚¬ìš© ê°€ëŠ¥í•œ ë©”ëª¨ë¦¬: ~${totalMemoryGB}GB`));
    
    if (totalMemoryGB < 8) {
      console.log(chalk.yellow('âš ï¸ ë©”ëª¨ë¦¬ê°€ ë¶€ì¡±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìµœì†Œ 8GB ê¶Œì¥'));
    }

    // í•„ìš”í•œ ë””ìŠ¤í¬ ê³µê°„ ì•ˆë‚´
    const totalSize = this.models.reduce((sum, model) => {
      return sum + parseInt(model.estimatedSize.replace('~', '').replace('GB', ''));
    }, 0);

    console.log(chalk.blue(`ğŸ’¿ í•„ìš”í•œ ë””ìŠ¤í¬ ê³µê°„: ~${totalSize}GB`));
    console.log(chalk.green('âœ… ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­ í™•ì¸ ì™„ë£Œ'));
  }

  async checkOllamaService() {
    console.log(chalk.yellow('ğŸ” Ollama ì„œë¹„ìŠ¤ í™•ì¸ ì¤‘...'));

    try {
      const response = await axios.get(`${this.ollamaEndpoint}/api/version`, {
        timeout: 5000
      });

      console.log(chalk.green('âœ… Ollama ì„œë¹„ìŠ¤ ì‹¤í–‰ ì¤‘'));
      console.log(chalk.gray(`   ë²„ì „: ${response.data.version || 'Unknown'}`));

    } catch (error) {
      if (error.code === 'ECONNREFUSED') {
        console.log(chalk.red('âŒ Ollama ì„œë¹„ìŠ¤ê°€ ì‹¤í–‰ë˜ì§€ ì•Šê³  ìˆìŠµë‹ˆë‹¤.'));
        console.log(chalk.yellow('ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ Ollamaë¥¼ ì‹œì‘í•˜ì„¸ìš”:'));
        console.log(chalk.white('  ollama serve'));
        throw new Error('Ollama ì„œë¹„ìŠ¤ë¥¼ ë¨¼ì € ì‹œì‘í•´ì£¼ì„¸ìš”.');
      }
      throw error;
    }
  }

  async checkExistingModels() {
    console.log(chalk.yellow('ğŸ“¦ ì„¤ì¹˜ëœ ëª¨ë¸ í™•ì¸ ì¤‘...'));

    try {
      const response = await axios.get(`${this.ollamaEndpoint}/api/tags`);
      const installedModels = response.data.models || [];
      const installedNames = installedModels.map(m => m.name);

      console.log(chalk.blue(`í˜„ì¬ ì„¤ì¹˜ëœ ëª¨ë¸: ${installedNames.length}ê°œ`));

      for (const model of this.models) {
        if (installedNames.includes(model.name)) {
          console.log(chalk.green(`âœ… ${model.name} - ì´ë¯¸ ì„¤ì¹˜ë¨`));
          this.installedModels.push(model.name);
        } else {
          console.log(chalk.yellow(`â³ ${model.name} - ì„¤ì¹˜ í•„ìš”`));
        }
      }

    } catch (error) {
      console.error(chalk.red('ëª¨ë¸ ëª©ë¡ í™•ì¸ ì‹¤íŒ¨:'), error.message);
      throw error;
    }
  }

  async installModels() {
    const modelsToInstall = this.models.filter(model =>
      !this.installedModels.includes(model.name)
    );

    if (modelsToInstall.length === 0) {
      console.log(chalk.green('âœ… ëª¨ë“  í•„ìš”í•œ ëª¨ë¸ì´ ì´ë¯¸ ì„¤ì¹˜ë˜ì–´ ìˆìŠµë‹ˆë‹¤.'));
      return;
    }

    console.log(chalk.yellow(`ğŸ”„ ${modelsToInstall.length}ê°œ ëª¨ë¸ ì„¤ì¹˜ ì‹œì‘...`));

    for (const model of modelsToInstall) {
      try {
        console.log(chalk.cyan(`\nğŸ“¥ ${model.name} ì„¤ì¹˜ ì¤‘...`));
        console.log(chalk.gray(`   ì„¤ëª…: ${model.description}`));
        console.log(chalk.gray(`   ì˜ˆìƒ í¬ê¸°: ${model.estimatedSize}`));
        console.log(chalk.gray(`   ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: ${model.memoryUsage}`));

        await this.installSingleModel(model);
        
        console.log(chalk.green(`âœ… ${model.name} ì„¤ì¹˜ ì™„ë£Œ`));
        this.installedModels.push(model.name);

      } catch (error) {
        console.error(chalk.red(`âŒ ${model.name} ì„¤ì¹˜ ì‹¤íŒ¨:`, error.message));
        this.failedModels.push({
          name: model.name,
          error: error.message
        });
      }
    }
  }

  async installSingleModel(model) {
    return new Promise((resolve, reject) => {
      const pullProcess = spawn('ollama', ['pull', model.name], {
        stdio: ['pipe', 'pipe', 'pipe']
      });

      let output = '';
      let hasProgress = false;
      let lastProgress = '';

      pullProcess.stdout.on('data', (data) => {
        const text = data.toString();
        output += text;

        // ì§„í–‰ë¥  í‘œì‹œ
        const progressMatch = text.match(/(\d+)%/);
        if (progressMatch) {
          const progress = progressMatch[1];
          if (progress !== lastProgress) {
            process.stdout.write(`\r${chalk.blue(`   ì§„í–‰ë¥ : ${progress}%`)}`);
            lastProgress = progress;
            hasProgress = true;
          }
        }

        // ìƒíƒœ ë©”ì‹œì§€ í‘œì‹œ
        if (text.includes('pulling')) {
          process.stdout.write(`\r${chalk.yellow('   ë‹¤ìš´ë¡œë“œ ì¤‘...')}`);
        } else if (text.includes('verifying')) {
          process.stdout.write(`\r${chalk.yellow('   ê²€ì¦ ì¤‘...')}`);
        } else if (text.includes('writing')) {
          process.stdout.write(`\r${chalk.yellow('   íŒŒì¼ ìƒì„± ì¤‘...')}`);
        } else if (text.includes('success')) {
          process.stdout.write(`\r${chalk.green('   ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!')}`);
        }
      });

      pullProcess.stderr.on('data', (data) => {
        const errorText = data.toString();
        if (!errorText.includes('progress')) {
          console.error(chalk.red(`   ì˜¤ë¥˜: ${errorText.trim()}`));
        }
      });

      pullProcess.on('close', (code) => {
        if (hasProgress) {
          console.log(); // ìƒˆ ì¤„ ì¶”ê°€
        }

        if (code === 0) {
          resolve();
        } else {
          reject(new Error(`ëª¨ë¸ ì„¤ì¹˜ ì‹¤íŒ¨ (ì¢…ë£Œ ì½”ë“œ: ${code})`));
        }
      });

      pullProcess.on('error', (error) => {
        reject(new Error(`í”„ë¡œì„¸ìŠ¤ ì˜¤ë¥˜: ${error.message}`));
      });
    });
  }

  async testInstalledModels() {
    console.log(chalk.yellow('\nğŸ§ª ì„¤ì¹˜ëœ ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì¤‘...'));

    for (const modelName of this.installedModels) {
      try {
        console.log(chalk.blue(`í…ŒìŠ¤íŠ¸ ì¤‘: ${modelName}`));
        
        const testResult = await this.testSingleModel(modelName);
        
        if (testResult.success) {
          console.log(chalk.green(`âœ… ${modelName} í…ŒìŠ¤íŠ¸ ì„±ê³µ`));
          console.log(chalk.gray(`   ì‘ë‹µ ì‹œê°„: ${testResult.responseTime}ms`));
        } else {
          console.log(chalk.red(`âŒ ${modelName} í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨`));
        }

      } catch (error) {
        console.log(chalk.red(`âŒ ${modelName} í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜:`, error.message));
      }
    }
  }

  async testSingleModel(modelName) {
    const startTime = Date.now();
    
    try {
      const response = await axios.post(`${this.ollamaEndpoint}/api/generate`, {
        model: modelName,
        prompt: 'Hello, respond with just "OK"',
        stream: false
      }, {
        timeout: 30000
      });

      const responseTime = Date.now() - startTime;
      
      return {
        success: true,
        responseTime: responseTime,
        response: response.data.response
      };

    } catch (error) {
      return {
        success: false,
        error: error.message,
        responseTime: Date.now() - startTime
      };
    }
  }

  async updateConfigFiles() {
    console.log(chalk.yellow('âš™ï¸ ì„¤ì • íŒŒì¼ ì—…ë°ì´íŠ¸ ì¤‘...'));

    try {
      // ëª¨ë¸ ì„¤ì • íŒŒì¼ ìƒì„±
      const modelConfig = {
        'llama-router': {
          model: 'llama3.2:3b',
          endpoint: this.ollamaEndpoint,
          temperature: 0.1,
          max_tokens: 512,
          role: 'routing',
          description: 'ë¹ ë¥¸ ì˜ë„ íŒŒì•… ë° ë¼ìš°íŒ… ê²°ì •',
          memory_limit: '6GB',
          auto_unload: false,
          optimization: {
            context_length: 4096,
            batch_size: 1,
            num_threads: 4
          }
        },
        'qwen-processor': {
          model: 'qwen2.5:14b',
          endpoint: this.ollamaEndpoint,
          temperature: 0.3,
          max_tokens: 2048,
          role: 'processing',
          description: 'ë³µì¡í•œ ì½”ë“œ ìƒì„± ë° ë¶„ì„ ì‘ì—…',
          memory_limit: '28GB',
          auto_unload: true,
          auto_unload_timeout: 600000,
          optimization: {
            context_length: 8192,
            batch_size: 1,
            num_threads: 8
          }
        }
      };

      // models ë””ë ‰í† ë¦¬ ìƒì„±
      await fs.mkdir('./models', { recursive: true });

      // ì„¤ì • íŒŒì¼ ì €ì¥
      await fs.writeFile(
        './models/model-configs.json',
        JSON.stringify(modelConfig, null, 2)
      );

      console.log(chalk.green('âœ… ì„¤ì • íŒŒì¼ ìƒì„± ì™„ë£Œ'));

    } catch (error) {
      console.error(chalk.red('ì„¤ì • íŒŒì¼ ìƒì„± ì‹¤íŒ¨:'), error.message);
    }
  }

  showCompletionMessage() {
    console.log(chalk.green('\nğŸ‰ ëª¨ë¸ ì„¤ì¹˜ ì™„ë£Œ!'));
    console.log(chalk.gray('=' * 50));

    // ì„¤ì¹˜ ìš”ì•½
    console.log(chalk.cyan('ğŸ“Š ì„¤ì¹˜ ìš”ì•½:'));
    console.log(chalk.white(`   ì„±ê³µ: ${this.installedModels.length}ê°œ ëª¨ë¸`));
    console.log(chalk.white(`   ì‹¤íŒ¨: ${this.failedModels.length}ê°œ ëª¨ë¸`));

    // ì„¤ì¹˜ëœ ëª¨ë¸ ëª©ë¡
    if (this.installedModels.length > 0) {
      console.log(chalk.green('\nâœ… ì„¤ì¹˜ëœ ëª¨ë¸:'));
      this.installedModels.forEach(model => {
        const modelInfo = this.models.find(m => m.name === model);
        console.log(chalk.white(`   â€¢ ${model} (${modelInfo?.role || 'unknown'})`));
      });
    }

    // ì‹¤íŒ¨í•œ ëª¨ë¸ ëª©ë¡
    if (this.failedModels.length > 0) {
      console.log(chalk.red('\nâŒ ì‹¤íŒ¨í•œ ëª¨ë¸:'));
      this.failedModels.forEach(model => {
        console.log(chalk.white(`   â€¢ ${model.name}: ${model.error}`));
      });
    }

    // ë‹¤ìŒ ë‹¨ê³„ ì•ˆë‚´
    console.log(chalk.yellow('\nğŸš€ ë‹¤ìŒ ë‹¨ê³„:'));
    console.log(chalk.white('   1. npm run cli ë˜ëŠ” node mcp-cli.js ì‹¤í–‰'));
    console.log(chalk.white('   2. "ì•ˆë…•í•˜ì„¸ìš”" ëª…ë ¹ìœ¼ë¡œ í…ŒìŠ¤íŠ¸'));
    console.log(chalk.white('   3. "ìƒíƒœ í™•ì¸í•´ì£¼ì„¸ìš”" ëª…ë ¹ìœ¼ë¡œ ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸'));

    // ì‚¬ìš© ê°€ëŠ¥í•œ ëª…ë ¹ì–´
    console.log(chalk.blue('\nğŸ’¡ ì‚¬ìš© ê°€ëŠ¥í•œ ëª…ë ¹ì–´:'));
    console.log(chalk.white('   â€¢ npm run cli    - MCP CLI ì‹¤í–‰'));
    console.log(chalk.white('   â€¢ npm run start  - MCP ì„œë²„ ì‹¤í–‰'));
    console.log(chalk.white('   â€¢ npm run test   - í†µí•© í…ŒìŠ¤íŠ¸'));

    // ë¬¸ì œ í•´ê²° ì •ë³´
    if (this.failedModels.length > 0) {
      console.log(chalk.yellow('\nğŸ”§ ë¬¸ì œ í•´ê²°:'));
      console.log(chalk.white('   â€¢ ì‹¤íŒ¨í•œ ëª¨ë¸ì€ ìˆ˜ë™ìœ¼ë¡œ ì„¤ì¹˜ ê°€ëŠ¥: ollama pull <model-name>'));
      console.log(chalk.white('   â€¢ ë””ìŠ¤í¬ ê³µê°„ ë¶€ì¡± ì‹œ ë¶ˆí•„ìš”í•œ íŒŒì¼ ì‚­ì œ'));
      console.log(chalk.white('   â€¢ ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ ë‹¤ë¥¸ í”„ë¡œê·¸ë¨ ì¢…ë£Œ'));
    }

    console.log(chalk.gray('\nëª¨ë¸ ì„¤ì¹˜ ìŠ¤í¬ë¦½íŠ¸ ì™„ë£Œ'));
  }
}

// ë©”ì¸ ì‹¤í–‰
async function main() {
  const setup = new ModelSetup();
  await setup.run();
}

// ì—ëŸ¬ í•¸ë“¤ë§
process.on('unhandledRejection', (reason, promise) => {
  console.error(chalk.red('Unhandled Rejection:'), reason);
  process.exit(1);
});

process.on('uncaughtException', (error) => {
  console.error(chalk.red('Uncaught Exception:'), error);
  process.exit(1);
});

// SIGINT í•¸ë“¤ëŸ¬ (Ctrl+C)
process.on('SIGINT', () => {
  console.log(chalk.yellow('\nì„¤ì¹˜ ì¤‘ë‹¨ë¨'));
  process.exit(0);
});

main().catch(console.error);
