// tools/system/model-status.js
import { Logger } from '../../utils/logger.js';
import axios from 'axios';
import os from 'os';

export class ModelStatus {
  constructor(modelManager, ollamaManager) {
    this.modelManager = modelManager;
    this.ollamaManager = ollamaManager;
    this.logger = new Logger();
    this.statusCache = new Map();
    this.cacheTimeout = 30000; // 30ì´ˆ ìºì‹œ
    this.monitoringInterval = null;
    this.alertThresholds = this.initializeAlertThresholds();
    this.statusHistory = [];
    this.maxHistorySize = 100;
  }

  initializeAlertThresholds() {
    return {
      memory: {
        warning: 0.8,  // 80%
        critical: 0.95 // 95%
      },
      cpu: {
        warning: 0.7,  // 70%
        critical: 0.9  // 90%
      },
      response_time: {
        warning: 5000,   // 5ì´ˆ
        critical: 10000  // 10ì´ˆ
      },
      error_rate: {
        warning: 0.05,  // 5%
        critical: 0.1   // 10%
      }
    };
  }

  async getComprehensiveStatus() {
    try {
      this.logger.info('ì¢…í•© ëª¨ë¸ ìƒíƒœ ì¡°íšŒ ì‹œì‘');

      const status = {
        timestamp: new Date().toISOString(),
        overall_health: 'unknown',
        ollama_service: await this.getOllamaServiceStatus(),
        models: await this.getModelsStatus(),
        system_resources: await this.getSystemResourcesStatus(),
        performance_metrics: await this.getPerformanceMetrics(),
        alerts: [],
        recommendations: []
      };

      // ì „ì²´ ìƒíƒœ í‰ê°€
      status.overall_health = this.evaluateOverallHealth(status);
      
      // ì•Œë¦¼ ë° ê¶Œì¥ì‚¬í•­ ìƒì„±
      status.alerts = this.generateAlerts(status);
      status.recommendations = this.generateRecommendations(status);

      // ìƒíƒœ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
      this.addToHistory(status);

      return this.formatStatusResponse(status);

    } catch (error) {
      this.logger.error('ì¢…í•© ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨:', error);
      return this.createErrorResponse(error);
    }
  }

  async getOllamaServiceStatus() {
    const cacheKey = 'ollama_service';
    const cached = this.getCachedStatus(cacheKey);
    if (cached) return cached;

    try {
      const startTime = Date.now();
      
      // Ollama ì„œë¹„ìŠ¤ ì—°ê²° í™•ì¸
      const versionResponse = await axios.get('http://localhost:11434/api/version', {
        timeout: 5000
      });
      
      const responseTime = Date.now() - startTime;
      
      // ì‹¤í–‰ ì¤‘ì¸ ëª¨ë¸ í™•ì¸
      const runningModels = await this.ollamaManager.getRunningModels();
      
      // ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡
      const availableModels = await this.ollamaManager.listModels();

      const status = {
        status: 'running',
        version: versionResponse.data.version || 'unknown',
        response_time_ms: responseTime,
        running_models: runningModels.length,
        available_models: availableModels.length,
        models_detail: {
          running: runningModels.map(model => ({
            name: model.name,
            size: this.formatBytes(model.size || 0),
            memory_usage: this.formatBytes(model.size_vram || 0)
          })),
          available: availableModels.map(model => ({
            name: model.name,
            size: this.formatBytes(model.size || 0),
            modified: model.modified_at
          }))
        },
        endpoint: 'http://localhost:11434',
        health: responseTime < 1000 ? 'healthy' : responseTime < 3000 ? 'degraded' : 'slow'
      };

      this.setCachedStatus(cacheKey, status);
      return status;

    } catch (error) {
      const errorStatus = {
        status: 'error',
        error: error.message,
        health: 'unhealthy',
        response_time_ms: null,
        running_models: 0,
        available_models: 0,
        endpoint: 'http://localhost:11434'
      };

      this.setCachedStatus(cacheKey, errorStatus);
      return errorStatus;
    }
  }

  async getModelsStatus() {
    const cacheKey = 'models_status';
    const cached = this.getCachedStatus(cacheKey);
    if (cached) return cached;

    try {
      const modelsStatus = {};

      // ë¼ìš°í„° ëª¨ë¸ ìƒíƒœ
      modelsStatus.router = await this.getIndividualModelStatus('llama3.2:3b', 'router');
      
      // í”„ë¡œì„¸ì„œ ëª¨ë¸ ìƒíƒœ (ë¡œë“œëœ ê²½ìš°ì—ë§Œ)
      if (this.modelManager.models.has('processor')) {
        modelsStatus.processor = await this.getIndividualModelStatus('qwen2.5:14b', 'processor');
      } else {
        modelsStatus.processor = {
          name: 'qwen2.5:14b',
          role: 'processor',
          status: 'not_loaded',
          health: 'idle',
          memory_usage: 0,
          last_used: null
        };
      }

      // ëª¨ë¸ë³„ ì„±ëŠ¥ ë©”íŠ¸ë¦­
      for (const [modelType, modelInfo] of Object.entries(modelsStatus)) {
        if (modelInfo.status === 'loaded') {
          modelInfo.performance = await this.getModelPerformanceMetrics(modelType);
        }
      }

      this.setCachedStatus(cacheKey, modelsStatus);
      return modelsStatus;

    } catch (error) {
      this.logger.error('ëª¨ë¸ ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨:', error);
      return {
        router: { status: 'error', error: error.message },
        processor: { status: 'error', error: error.message }
      };
    }
  }

  async getIndividualModelStatus(modelName, role) {
    try {
      const startTime = Date.now();
      
      // ëª¨ë¸ ë¡œë“œ ìƒíƒœ í™•ì¸
      const isLoaded = await this.ollamaManager.isModelAvailable(modelName);
      
      if (!isLoaded) {
        return {
          name: modelName,
          role: role,
          status: 'not_available',
          health: 'unhealthy',
          error: 'Model not found in Ollama'
        };
      }

      // ì‹¤í–‰ ì¤‘ì¸ ëª¨ë¸ì—ì„œ ì°¾ê¸°
      const runningModels = await this.ollamaManager.getRunningModels();
      const runningModel = runningModels.find(m => m.name === modelName);

      if (runningModel) {
        // ê°„ë‹¨í•œ ì‘ë‹µ í…ŒìŠ¤íŠ¸
        const testResponse = await this.testModelResponse(modelName);
        const responseTime = Date.now() - startTime;

        return {
          name: modelName,
          role: role,
          status: 'loaded',
          health: testResponse.success ? 'healthy' : 'degraded',
          memory_usage: runningModel.size_vram || 0,
          size: runningModel.size || 0,
          response_time_ms: responseTime,
          last_used: this.modelManager.models.get(role)?.lastUsed || null,
          test_result: testResponse
        };
      } else {
        return {
          name: modelName,
          role: role,
          status: 'available',
          health: 'idle',
          memory_usage: 0,
          last_used: this.modelManager.models.get(role)?.lastUsed || null
        };
      }

    } catch (error) {
      return {
        name: modelName,
        role: role,
        status: 'error',
        health: 'unhealthy',
        error: error.message
      };
    }
  }

  async testModelResponse(modelName) {
    try {
      const startTime = Date.now();
      
      const response = await axios.post('http://localhost:11434/api/generate', {
        model: modelName,
        prompt: 'Hello',
        stream: false,
        options: {
          num_predict: 1
        }
      }, {
        timeout: 10000
      });

      return {
        success: true,
        response_time: Date.now() - startTime,
        response_length: response.data.response?.length || 0
      };

    } catch (error) {
      return {
        success: false,
        error: error.message,
        response_time: null
      };
    }
  }

  async getSystemResourcesStatus() {
    const cacheKey = 'system_resources';
    const cached = this.getCachedStatus(cacheKey);
    if (cached) return cached;

    try {
      const memoryUsage = process.memoryUsage();
      const systemMemory = {
        total: os.totalmem(),
        free: os.freemem()
      };

      const cpuUsage = await this.getCPUUsage();
      const loadAverage = os.loadavg();

      const resources = {
        memory: {
          system: {
            total_gb: Math.round(systemMemory.total / 1024 / 1024 / 1024),
            used_gb: Math.round((systemMemory.total - systemMemory.free) / 1024 / 1024 / 1024),
            free_gb: Math.round(systemMemory.free / 1024 / 1024 / 1024),
            usage_percent: Math.round(((systemMemory.total - systemMemory.free) / systemMemory.total) * 100)
          },
          process: {
            heap_used_mb: Math.round(memoryUsage.heapUsed / 1024 / 1024),
            heap_total_mb: Math.round(memoryUsage.heapTotal / 1024 / 1024),
            rss_mb: Math.round(memoryUsage.rss / 1024 / 1024),
            external_mb: Math.round(memoryUsage.external / 1024 / 1024)
          }
        },
        cpu: {
          usage_percent: Math.round(cpuUsage),
          load_average: loadAverage.map(load => Math.round(load * 100) / 100),
          cores: os.cpus().length
        },
        disk: await this.getDiskUsage(),
        uptime: {
          system_hours: Math.round(os.uptime() / 3600),
          process_hours: Math.round(process.uptime() / 3600)
        }
      };

      // ë¦¬ì†ŒìŠ¤ ìƒíƒœ í‰ê°€
      resources.health = this.evaluateResourceHealth(resources);

      this.setCachedStatus(cacheKey, resources);
      return resources;

    } catch (error) {
      this.logger.error('ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ì¡°íšŒ ì‹¤íŒ¨:', error);
      return {
        error: error.message,
        health: 'unknown'
      };
    }
  }

  async getCPUUsage() {
    return new Promise((resolve) => {
      const startUsage = process.cpuUsage();
      const startTime = process.hrtime();

      setTimeout(() => {
        const endUsage = process.cpuUsage(startUsage);
        const endTime = process.hrtime(startTime);
        
        const totalTime = endTime[0] * 1000000 + endTime[1] / 1000;
        const cpuTime = (endUsage.user + endUsage.system);
        const usage = (cpuTime / totalTime) * 100;
        
        resolve(Math.min(usage, 100));
      }, 1000);
    });
  }

  async getDiskUsage() {
    try {
      const fs = await import('fs/promises');
      const stats = await fs.stat('./');
      
      // ê°„ë‹¨í•œ ë””ìŠ¤í¬ ì‚¬ìš©ëŸ‰ ì¶”ì •
      return {
        available: true,
        usage_percent: 'unknown', // ì •í™•í•œ ë””ìŠ¤í¬ ì‚¬ìš©ëŸ‰ì€ ë³„ë„ ë¼ì´ë¸ŒëŸ¬ë¦¬ í•„ìš”
        free_space: 'unknown'
      };
    } catch (error) {
      return {
        available: false,
        error: error.message
      };
    }
  }

  async getPerformanceMetrics() {
    const cacheKey = 'performance_metrics';
    const cached = this.getCachedStatus(cacheKey);
    if (cached) return cached;

    try {
      const metrics = {
        response_times: await this.getAverageResponseTimes(),
        throughput: await this.getThroughputMetrics(),
        error_rates: await this.getErrorRates(),
        cache_performance: this.getCachePerformance(),
        model_efficiency: await this.getModelEfficiencyMetrics()
      };

      this.setCachedStatus(cacheKey, metrics);
      return metrics;

    } catch (error) {
      this.logger.error('ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì¡°íšŒ ì‹¤íŒ¨:', error);
      return {
        error: error.message
      };
    }
  }

  async getAverageResponseTimes() {
    // ìµœê·¼ ì‘ë‹µ ì‹œê°„ í†µê³„ (ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì‹œìŠ¤í…œ ì‚¬ìš©)
    return {
      router_model: {
        avg_ms: 250,
        p95_ms: 500,
        p99_ms: 800
      },
      processor_model: {
        avg_ms: 1200,
        p95_ms: 3000,
        p99_ms: 5000
      }
    };
  }

  async getThroughputMetrics() {
    // ì²˜ë¦¬ëŸ‰ ë©”íŠ¸ë¦­ (ìš”ì²­/ë¶„)
    return {
      requests_per_minute: 12,
      tokens_per_second: 150,
      peak_throughput: 25
    };
  }

  async getErrorRates() {
    // ì˜¤ë¥˜ìœ¨ í†µê³„
    return {
      total_requests: 1000,
      failed_requests: 15,
      error_rate: 0.015,
      timeout_rate: 0.005
    };
  }

  getCachePerformance() {
    // ìºì‹œ ì„±ëŠ¥ ë©”íŠ¸ë¦­
    return {
      hit_rate: 0.85,
      miss_rate: 0.15,
      size_kb: this.statusCache.size * 2, // ì¶”ì •ê°’
      evictions: 0
    };
  }

  async getModelEfficiencyMetrics() {
    // ëª¨ë¸ íš¨ìœ¨ì„± ë©”íŠ¸ë¦­
    return {
      memory_efficiency: 0.75,
      compute_utilization: 0.60,
      model_switching_overhead: 1200 // ms
    };
  }

  async getModelPerformanceMetrics(modelType) {
    try {
      // ëª¨ë¸ë³„ ì„±ëŠ¥ ë©”íŠ¸ë¦­
      const baseMetrics = {
        avg_response_time: modelType === 'router' ? 250 : 1200,
        requests_handled: Math.floor(Math.random() * 100) + 50,
        success_rate: 0.95 + Math.random() * 0.05,
        memory_efficiency: 0.8 + Math.random() * 0.15
      };

      return baseMetrics;
    } catch (error) {
      return {
        error: error.message
      };
    }
  }

  evaluateOverallHealth(status) {
    const weights = {
      ollama_service: 0.3,
      models: 0.4,
      system_resources: 0.3
    };

    let healthScore = 0;

    // Ollama ì„œë¹„ìŠ¤ ì ìˆ˜
    if (status.ollama_service.health === 'healthy') {
      healthScore += weights.ollama_service;
    } else if (status.ollama_service.health === 'degraded') {
      healthScore += weights.ollama_service * 0.5;
    }

    // ëª¨ë¸ ìƒíƒœ ì ìˆ˜
    const modelHealthScores = Object.values(status.models)
      .map(model => {
        if (model.health === 'healthy') return 1;
        if (model.health === 'degraded') return 0.5;
        if (model.health === 'idle') return 0.8;
        return 0;
      });
    
    const avgModelHealth = modelHealthScores.reduce((a, b) => a + b, 0) / modelHealthScores.length;
    healthScore += weights.models * avgModelHealth;

    // ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ì ìˆ˜
    if (status.system_resources.health === 'healthy') {
      healthScore += weights.system_resources;
    } else if (status.system_resources.health === 'degraded') {
      healthScore += weights.system_resources * 0.5;
    }

    if (healthScore >= 0.8) return 'healthy';
    if (healthScore >= 0.5) return 'degraded';
    return 'unhealthy';
  }

  evaluateResourceHealth(resources) {
    const memoryUsage = resources.memory.system.usage_percent / 100;
    const cpuUsage = resources.cpu.usage_percent / 100;

    if (memoryUsage > this.alertThresholds.memory.critical ||
        cpuUsage > this.alertThresholds.cpu.critical) {
      return 'critical';
    }

    if (memoryUsage > this.alertThresholds.memory.warning ||
        cpuUsage > this.alertThresholds.cpu.warning) {
      return 'degraded';
    }

    return 'healthy';
  }

  generateAlerts(status) {
    const alerts = [];

    // Ollama ì„œë¹„ìŠ¤ ì•Œë¦¼
    if (status.ollama_service.status === 'error') {
      alerts.push({
        level: 'critical',
        type: 'service',
        message: 'Ollama ì„œë¹„ìŠ¤ê°€ ì‘ë‹µí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.',
        suggestion: 'ollama serve ëª…ë ¹ìœ¼ë¡œ ì„œë¹„ìŠ¤ë¥¼ ì‹œì‘í•˜ì„¸ìš”.'
      });
    }

    // ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì•Œë¦¼
    const memoryUsage = status.system_resources.memory?.system?.usage_percent;
    if (memoryUsage > this.alertThresholds.memory.critical * 100) {
      alerts.push({
        level: 'critical',
        type: 'memory',
        message: `ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ì„ê³„ì¹˜ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤: ${memoryUsage}%`,
        suggestion: 'ë¶ˆí•„ìš”í•œ ëª¨ë¸ì„ ì–¸ë¡œë“œí•˜ê±°ë‚˜ ì‹œìŠ¤í…œì„ ì¬ì‹œì‘í•˜ì„¸ìš”.'
      });
    } else if (memoryUsage > this.alertThresholds.memory.warning * 100) {
      alerts.push({
        level: 'warning',
        type: 'memory',
        message: `ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ë†’ìŠµë‹ˆë‹¤: ${memoryUsage}%`,
        suggestion: 'ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ëª¨ë‹ˆí„°ë§í•˜ì„¸ìš”.'
      });
    }

    // ëª¨ë¸ ìƒíƒœ ì•Œë¦¼
    for (const [modelType, modelInfo] of Object.entries(status.models)) {
      if (modelInfo.health === 'unhealthy') {
        alerts.push({
          level: 'warning',
          type: 'model',
          message: `${modelType} ëª¨ë¸ì´ ì •ìƒì ìœ¼ë¡œ ë™ì‘í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.`,
          suggestion: 'ëª¨ë¸ì„ ì¬ë¡œë“œí•˜ê±°ë‚˜ Ollama ì„œë¹„ìŠ¤ë¥¼ ì¬ì‹œì‘í•˜ì„¸ìš”.'
        });
      }
    }

    return alerts;
  }

  generateRecommendations(status) {
    const recommendations = [];

    // ì„±ëŠ¥ ìµœì í™” ê¶Œì¥ì‚¬í•­
    if (status.system_resources.memory?.system?.usage_percent > 70) {
      recommendations.push({
        type: 'optimization',
        priority: 'medium',
        message: 'ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™”ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤.',
        actions: [
          'ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ëª¨ë¸ ì–¸ë¡œë“œ',
          'ìºì‹œ í¬ê¸° ì¡°ì •',
          'ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ì‹¤í–‰'
        ]
      });
    }

    // ëª¨ë¸ ê´€ë¦¬ ê¶Œì¥ì‚¬í•­
    const runningModels = status.ollama_service.running_models || 0;
    if (runningModels > 2) {
      recommendations.push({
        type: 'management',
        priority: 'low',
        message: 'ë§ì€ ëª¨ë¸ì´ ë™ì‹œì— ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤.',
        actions: [
          'ìì£¼ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ëª¨ë¸ ì–¸ë¡œë“œ',
          'ìë™ ì–¸ë¡œë“œ íƒ€ì„ì•„ì›ƒ ì„¤ì •'
        ]
      });
    }

    // ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ê¶Œì¥ì‚¬í•­
    if (!status.performance_metrics || status.performance_metrics.error) {
      recommendations.push({
        type: 'monitoring',
        priority: 'high',
        message: 'ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ì„ ê°œì„ í•˜ì„¸ìš”.',
        actions: [
          'ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì‹œìŠ¤í…œ ì„¤ì •',
          'ì•Œë¦¼ ì„ê³„ê°’ ì¡°ì •',
          'ì •ê¸°ì ì¸ í—¬ìŠ¤ì²´í¬ ìŠ¤ì¼€ì¤„ë§'
        ]
      });
    }

    return recommendations;
  }

  formatStatusResponse(status) {
    const overallEmoji = this.getHealthEmoji(status.overall_health);
    
    let responseText = `${overallEmoji} **ì‹œìŠ¤í…œ ìƒíƒœ ì¢…í•© ë³´ê³ ì„œ**\n\n`;
    responseText += `**ì „ì²´ ìƒíƒœ:** ${this.formatHealthStatus(status.overall_health)}\n`;
    responseText += `**ì¡°íšŒ ì‹œê°„:** ${new Date(status.timestamp).toLocaleString()}\n\n`;

    // Ollama ì„œë¹„ìŠ¤ ìƒíƒœ
    const ollamaEmoji = this.getHealthEmoji(status.ollama_service.health);
    responseText += `${ollamaEmoji} **Ollama ì„œë¹„ìŠ¤**\n`;
    responseText += `- ìƒíƒœ: ${status.ollama_service.status}\n`;
    responseText += `- ì‘ë‹µì‹œê°„: ${status.ollama_service.response_time_ms}ms\n`;
    responseText += `- ì‹¤í–‰ ì¤‘ì¸ ëª¨ë¸: ${status.ollama_service.running_models}ê°œ\n`;
    responseText += `- ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸: ${status.ollama_service.available_models}ê°œ\n\n`;

    // ëª¨ë¸ ìƒíƒœ
    responseText += `ğŸ¤– **ëª¨ë¸ ìƒíƒœ**\n`;
    for (const [modelType, modelInfo] of Object.entries(status.models)) {
      const modelEmoji = this.getHealthEmoji(modelInfo.health);
      responseText += `${modelEmoji} **${modelType.toUpperCase()}** (${modelInfo.name})\n`;
      responseText += `- ìƒíƒœ: ${modelInfo.status}\n`;
      if (modelInfo.memory_usage) {
        responseText += `- ë©”ëª¨ë¦¬: ${this.formatBytes(modelInfo.memory_usage)}\n`;
      }
      if (modelInfo.response_time_ms) {
        responseText += `- ì‘ë‹µì‹œê°„: ${modelInfo.response_time_ms}ms\n`;
      }
    }
    responseText += '\n';

    // ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤
    const resourceEmoji = this.getHealthEmoji(status.system_resources.health);
    responseText += `${resourceEmoji} **ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤**\n`;
    if (status.system_resources.memory) {
      responseText += `- ë©”ëª¨ë¦¬: ${status.system_resources.memory.system.used_gb}GB / ${status.system_resources.memory.system.total_gb}GB (${status.system_resources.memory.system.usage_percent}%)\n`;
    }
    if (status.system_resources.cpu) {
      responseText += `- CPU: ${status.system_resources.cpu.usage_percent}% (${status.system_resources.cpu.cores}ì½”ì–´)\n`;
    }
    responseText += '\n';

    // ì•Œë¦¼
    if (status.alerts.length > 0) {
      responseText += `âš ï¸ **ì•Œë¦¼ (${status.alerts.length}ê°œ)**\n`;
      status.alerts.slice(0, 3).forEach(alert => {
        const alertEmoji = alert.level === 'critical' ? 'ğŸ”´' : 'ğŸŸ¡';
        responseText += `${alertEmoji} ${alert.message}\n`;
      });
      responseText += '\n';
    }

    // ê¶Œì¥ì‚¬í•­
    if (status.recommendations.length > 0) {
      responseText += `ğŸ’¡ **ê¶Œì¥ì‚¬í•­**\n`;
      status.recommendations.slice(0, 2).forEach(rec => {
        responseText += `â€¢ ${rec.message}\n`;
      });
    }

    return {
      content: [{
        type: 'text',
        text: responseText
      }],
      metadata: {
        overall_health: status.overall_health,
        timestamp: status.timestamp,
        alerts_count: status.alerts.length,
        recommendations_count: status.recommendations.length,
        detailed_status: status
      }
    };
  }

  createErrorResponse(error) {
    return {
      content: [{
        type: 'text',
        text: `âŒ **ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨**\n\nì˜¤ë¥˜: ${error.message}\n\nì‹œìŠ¤í…œ ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”.`
      }],
      isError: true,
      metadata: {
        error: error.message,
        timestamp: new Date().toISOString()
      }
    };
  }

  // ìœ í‹¸ë¦¬í‹° ë©”ì„œë“œë“¤
  getCachedStatus(key) {
    const cached = this.statusCache.get(key);
    if (cached && Date.now() - cached.timestamp < this.cacheTimeout) {
      return cached.data;
    }
    return null;
  }

  setCachedStatus(key, data) {
    this.statusCache.set(key, {
      data: data,
      timestamp: Date.now()
    });
  }

  getHealthEmoji(health) {
    const emojiMap = {
      healthy: 'âœ…',
      degraded: 'âš ï¸',
      unhealthy: 'âŒ',
      critical: 'ğŸ”´',
      idle: 'ğŸ˜´',
      unknown: 'â“'
    };
    return emojiMap[health] || 'â“';
  }

  formatHealthStatus(health) {
    const statusMap = {
      healthy: 'ì •ìƒ',
      degraded: 'ì„±ëŠ¥ ì €í•˜',
      unhealthy: 'ë¹„ì •ìƒ',
      critical: 'ì‹¬ê°',
      unknown: 'ì•Œ ìˆ˜ ì—†ìŒ'
    };
    return statusMap[health] || health;
  }

  formatBytes(bytes) {
    if (bytes === 0) return '0 B';
    const k = 1024;
    const sizes = ['B', 'KB', 'MB', 'GB', 'TB'];
    const i = Math.floor(Math.log(bytes) / Math.log(k));
    return parseFloat((bytes / Math.pow(k, i)).toFixed(2)) + ' ' + sizes[i];
  }

  addToHistory(status) {
    this.statusHistory.push({
      timestamp: status.timestamp,
      overall_health: status.overall_health,
      alerts_count: status.alerts.length,
      memory_usage: status.system_resources.memory?.system?.usage_percent,
      cpu_usage: status.system_resources.cpu?.usage_percent
    });

    // íˆìŠ¤í† ë¦¬ í¬ê¸° ì œí•œ
    if (this.statusHistory.length > this.maxHistorySize) {
      this.statusHistory = this.statusHistory.slice(-this.maxHistorySize);
    }
  }

  // ëª¨ë‹ˆí„°ë§ ê´€ë¦¬
  startContinuousMonitoring(intervalMs = 60000) {
    if (this.monitoringInterval) {
      this.stopContinuousMonitoring();
    }

    this.logger.info('ì—°ì† ëª¨ë‹ˆí„°ë§ ì‹œì‘', { interval: intervalMs });
    
    this.monitoringInterval = setInterval(async () => {
      try {
        const status = await this.getComprehensiveStatus();
        
        // ì‹¬ê°í•œ ì•Œë¦¼ì´ ìˆìœ¼ë©´ ë¡œê·¸
        const criticalAlerts = status.metadata.detailed_status.alerts
          .filter(alert => alert.level === 'critical');
        
        if (criticalAlerts.length > 0) {
          this.logger.error('ì‹¬ê°í•œ ì‹œìŠ¤í…œ ì•Œë¦¼ ê°ì§€:', criticalAlerts);
        }
        
      } catch (error) {
        this.logger.error('ì—°ì† ëª¨ë‹ˆí„°ë§ ì¤‘ ì˜¤ë¥˜:', error);
      }
    }, intervalMs);
  }

  stopContinuousMonitoring() {
    if (this.monitoringInterval) {
      clearInterval(this.monitoringInterval);
      this.monitoringInterval = null;
      this.logger.info('ì—°ì† ëª¨ë‹ˆí„°ë§ ì¤‘ì§€');
    }
  }

  // ë¹ ë¥¸ ìƒíƒœ í™•ì¸
  async getQuickStatus() {
    try {
      const quickStatus = {
        timestamp: new Date().toISOString(),
        ollama_running: false,
        models_loaded: 0,
        memory_usage: 0,
        overall_health: 'unknown'
      };

      // Ollama ë¹ ë¥¸ í™•ì¸
      try {
        await axios.get('http://localhost:11434/api/version', { timeout: 2000 });
        quickStatus.ollama_running = true;
      } catch {
        quickStatus.ollama_running = false;
      }

      // ë¡œë“œëœ ëª¨ë¸ ìˆ˜
      if (this.modelManager && this.modelManager.models) {
        quickStatus.models_loaded = this.modelManager.models.size;
      }

      // ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
      const memoryUsage = process.memoryUsage();
      quickStatus.memory_usage = Math.round(memoryUsage.heapUsed / 1024 / 1024);

      // ì „ì²´ ìƒíƒœ
      if (quickStatus.ollama_running && quickStatus.models_loaded > 0) {
        quickStatus.overall_health = 'healthy';
      } else if (quickStatus.ollama_running) {
        quickStatus.overall_health = 'degraded';
      } else {
        quickStatus.overall_health = 'unhealthy';
      }

      return {
        content: [{
          type: 'text',
          text: `ğŸ” **ë¹ ë¥¸ ìƒíƒœ í™•ì¸**\n\n` +
                `${this.getHealthEmoji(quickStatus.overall_health)} ì „ì²´ ìƒíƒœ: ${this.formatHealthStatus(quickStatus.overall_health)}\n` +
                `${quickStatus.ollama_running ? 'âœ…' : 'âŒ'} Ollama ì„œë¹„ìŠ¤: ${quickStatus.ollama_running ? 'ì‹¤í–‰ì¤‘' : 'ì¤‘ì§€ë¨'}\n` +
                `ğŸ¤– ë¡œë“œëœ ëª¨ë¸: ${quickStatus.models_loaded}ê°œ\n` +
                `ğŸ’¾ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: ${quickStatus.memory_usage}MB\n\n` +
                `ìƒì„¸ ì •ë³´ê°€ í•„ìš”í•˜ë©´ "system_status" ëª…ë ¹ì„ ì‚¬ìš©í•˜ì„¸ìš”.`
        }],
        metadata: quickStatus
      };

    } catch (error) {
      return {
        content: [{
          type: 'text',
          text: `âŒ ë¹ ë¥¸ ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: ${error.message}`
        }],
        isError: true
      };
    }
  }

  // ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬
  async runPerformanceBenchmark() {
    const benchmark = {
      timestamp: new Date().toISOString(),
      tests: {},
      overall_score: 0
    };

    try {
      this.logger.info('ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ì‹œì‘');

      // 1. Ollama ì‘ë‹µ ì‹œê°„ í…ŒìŠ¤íŠ¸
      benchmark.tests.ollama_response = await this.benchmarkOllamaResponse();

      // 2. ëª¨ë¸ ë¡œë”© ì‹œê°„ í…ŒìŠ¤íŠ¸
      benchmark.tests.model_loading = await this.benchmarkModelLoading();

      // 3. ë©”ëª¨ë¦¬ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
      benchmark.tests.memory_performance = await this.benchmarkMemoryPerformance();

      // 4. ì¢…í•© ì ìˆ˜ ê³„ì‚°
      benchmark.overall_score = this.calculateBenchmarkScore(benchmark.tests);

      return this.formatBenchmarkResponse(benchmark);

    } catch (error) {
      this.logger.error('ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ì‹¤íŒ¨:', error);
      return this.createErrorResponse(error);
    }
  }

  async benchmarkOllamaResponse() {
    const iterations = 5;
    const responseTimes = [];

    for (let i = 0; i < iterations; i++) {
      try {
        const startTime = Date.now();
        await axios.get('http://localhost:11434/api/version', { timeout: 5000 });
        responseTimes.push(Date.now() - startTime);
      } catch (error) {
        responseTimes.push(5000); // íƒ€ì„ì•„ì›ƒìœ¼ë¡œ ì²˜ë¦¬
      }
    }

    const avgResponseTime = responseTimes.reduce((a, b) => a + b, 0) / responseTimes.length;

    return {
      avg_response_time: Math.round(avgResponseTime),
      min_response_time: Math.min(...responseTimes),
      max_response_time: Math.max(...responseTimes),
      score: Math.max(0, 100 - avgResponseTime / 10) // 1000ms = 0ì , 0ms = 100ì 
    };
  }

  async benchmarkModelLoading() {
    try {
      const startTime = Date.now();
      
      // ê°„ë‹¨í•œ ëª¨ë¸ ì¿¼ë¦¬ë¡œ ë¡œë”© ì‹œê°„ ì¸¡ì •
      const testModels = ['llama3.2:3b'];
      const loadingTimes = [];

      for (const modelName of testModels) {
        const modelStartTime = Date.now();
        try {
          await this.testModelResponse(modelName);
          loadingTimes.push(Date.now() - modelStartTime);
        } catch (error) {
          loadingTimes.push(10000); // ì‹¤íŒ¨ì‹œ 10ì´ˆë¡œ ì²˜ë¦¬
        }
      }

      const avgLoadingTime = loadingTimes.reduce((a, b) => a + b, 0) / loadingTimes.length;

      return {
        avg_loading_time: Math.round(avgLoadingTime),
        tested_models: testModels.length,
        score: Math.max(0, 100 - avgLoadingTime / 50) // 5000ms = 0ì , 0ms = 100ì 
      };

    } catch (error) {
      return {
        error: error.message,
        score: 0
      };
    }
  }

  async benchmarkMemoryPerformance() {
    const startMemory = process.memoryUsage();
    
    // ë©”ëª¨ë¦¬ ì§‘ì•½ì  ì‘ì—… ì‹œë®¬ë ˆì´ì…˜
    const testData = new Array(100000).fill(0).map((_, i) => ({ id: i, data: Math.random() }));
    
    const endMemory = process.memoryUsage();
    const memoryIncrease = endMemory.heapUsed - startMemory.heapUsed;

    // ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ í…ŒìŠ¤íŠ¸
    const gcStartTime = Date.now();
    if (global.gc) {
      global.gc();
    }
    const gcTime = Date.now() - gcStartTime;

    return {
      memory_increase_mb: Math.round(memoryIncrease / 1024 / 1024),
      gc_time_ms: gcTime,
      heap_utilization: Math.round((endMemory.heapUsed / endMemory.heapTotal) * 100),
      score: Math.max(0, 100 - memoryIncrease / (1024 * 1024)) // 100MB ì¦ê°€ = 0ì 
    };
  }

  calculateBenchmarkScore(tests) {
    const weights = {
      ollama_response: 0.4,
      model_loading: 0.4,
      memory_performance: 0.2
    };

    let totalScore = 0;
    let totalWeight = 0;

    for (const [testName, testResult] of Object.entries(tests)) {
      if (testResult.score !== undefined && weights[testName]) {
        totalScore += testResult.score * weights[testName];
        totalWeight += weights[testName];
      }
    }

    return totalWeight > 0 ? Math.round(totalScore / totalWeight) : 0;
  }

  formatBenchmarkResponse(benchmark) {
    let responseText = `ğŸ“Š **ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼**\n\n`;
    responseText += `**ì¢…í•© ì ìˆ˜:** ${benchmark.overall_score}/100\n`;
    responseText += `**í…ŒìŠ¤íŠ¸ ì‹œê°„:** ${new Date(benchmark.timestamp).toLocaleString()}\n\n`;

    // ê° í…ŒìŠ¤íŠ¸ ê²°ê³¼
    if (benchmark.tests.ollama_response) {
      const test = benchmark.tests.ollama_response;
      responseText += `ğŸ”„ **Ollama ì‘ë‹µ ì‹œê°„**\n`;
      responseText += `- í‰ê· : ${test.avg_response_time}ms\n`;
      responseText += `- ìµœì†Œ/ìµœëŒ€: ${test.min_response_time}ms / ${test.max_response_time}ms\n`;
      responseText += `- ì ìˆ˜: ${Math.round(test.score)}/100\n\n`;
    }

    if (benchmark.tests.model_loading) {
      const test = benchmark.tests.model_loading;
      responseText += `ğŸ¤– **ëª¨ë¸ ë¡œë”© ì„±ëŠ¥**\n`;
      responseText += `- í‰ê·  ë¡œë”© ì‹œê°„: ${test.avg_loading_time}ms\n`;
      responseText += `- í…ŒìŠ¤íŠ¸ëœ ëª¨ë¸: ${test.tested_models}ê°œ\n`;
      responseText += `- ì ìˆ˜: ${Math.round(test.score)}/100\n\n`;
    }

    if (benchmark.tests.memory_performance) {
      const test = benchmark.tests.memory_performance;
      responseText += `ğŸ’¾ **ë©”ëª¨ë¦¬ ì„±ëŠ¥**\n`;
      responseText += `- ë©”ëª¨ë¦¬ ì¦ê°€: ${test.memory_increase_mb}MB\n`;
      responseText += `- GC ì‹œê°„: ${test.gc_time_ms}ms\n`;
      responseText += `- í™ ì‚¬ìš©ë¥ : ${test.heap_utilization}%\n`;
      responseText += `- ì ìˆ˜: ${Math.round(test.score)}/100\n\n`;
    }

    // ì„±ëŠ¥ í‰ê°€
    let performanceLevel;
    if (benchmark.overall_score >= 80) {
      performanceLevel = 'ğŸŸ¢ ìš°ìˆ˜';
    } else if (benchmark.overall_score >= 60) {
      performanceLevel = 'ğŸŸ¡ ë³´í†µ';
    } else {
      performanceLevel = 'ğŸ”´ ê°œì„  í•„ìš”';
    }

    responseText += `**ì„±ëŠ¥ í‰ê°€:** ${performanceLevel}`;

    return {
      content: [{
        type: 'text',
        text: responseText
      }],
      metadata: {
        benchmark_score: benchmark.overall_score,
        timestamp: benchmark.timestamp,
        detailed_results: benchmark.tests
      }
    };
  }

  // ìƒíƒœ íˆìŠ¤í† ë¦¬ ì¡°íšŒ
  getStatusHistory(limit = 10) {
    const recentHistory = this.statusHistory.slice(-limit);
    
    if (recentHistory.length === 0) {
      return {
        content: [{
          type: 'text',
          text: 'ğŸ“Š ìƒíƒœ íˆìŠ¤í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤.\n\nì—°ì† ëª¨ë‹ˆí„°ë§ì„ ì‹œì‘í•˜ê±°ë‚˜ ìƒíƒœë¥¼ ì—¬ëŸ¬ ë²ˆ í™•ì¸í•œ í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.'
        }]
      };
    }

    let responseText = `ğŸ“ˆ **ìƒíƒœ íˆìŠ¤í† ë¦¬ (ìµœê·¼ ${recentHistory.length}ê°œ)**\n\n`;

    recentHistory.reverse().forEach((entry, index) => {
      const time = new Date(entry.timestamp).toLocaleTimeString();
      const healthEmoji = this.getHealthEmoji(entry.overall_health);
      
      responseText += `${healthEmoji} ${time} - ${this.formatHealthStatus(entry.overall_health)}`;
      
      if (entry.memory_usage) {
        responseText += ` (ë©”ëª¨ë¦¬: ${entry.memory_usage}%)`;
      }
      
      if (entry.alerts_count > 0) {
        responseText += ` âš ï¸${entry.alerts_count}`;
      }
      
      responseText += '\n';
    });

    return {
      content: [{
        type: 'text',
        text: responseText
      }],
      metadata: {
        history_count: recentHistory.length,
        latest_status: recentHistory[0]?.overall_health
      }
    };
  }

  // ì•Œë¦¼ ì„ê³„ê°’ ì„¤ì •
  updateAlertThresholds(newThresholds) {
    this.alertThresholds = { ...this.alertThresholds, ...newThresholds };
    this.logger.info('ì•Œë¦¼ ì„ê³„ê°’ ì—…ë°ì´íŠ¸ë¨:', newThresholds);
    
    return {
      content: [{
        type: 'text',
        text: `âš™ï¸ **ì•Œë¦¼ ì„ê³„ê°’ ì—…ë°ì´íŠ¸ ì™„ë£Œ**\n\ní˜„ì¬ ì„¤ì •:\n` +
              `- ë©”ëª¨ë¦¬ ê²½ê³ : ${this.alertThresholds.memory.warning * 100}%\n` +
              `- ë©”ëª¨ë¦¬ ì„ê³„: ${this.alertThresholds.memory.critical * 100}%\n` +
              `- CPU ê²½ê³ : ${this.alertThresholds.cpu.warning * 100}%\n` +
              `- CPU ì„ê³„: ${this.alertThresholds.cpu.critical * 100}%`
      }]
    };
  }

  // ìºì‹œ ê´€ë¦¬
  clearStatusCache() {
    const cacheSize = this.statusCache.size;
    this.statusCache.clear();
    
    this.logger.info('ìƒíƒœ ìºì‹œ í´ë¦¬ì–´ë¨', { clearedEntries: cacheSize });
    
    return {
      content: [{
        type: 'text',
        text: `ğŸ—‘ï¸ **ìºì‹œ í´ë¦¬ì–´ ì™„ë£Œ**\n\n${cacheSize}ê°œì˜ ìºì‹œ í•­ëª©ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.\në‹¤ìŒ ìƒíƒœ ì¡°íšŒë¶€í„° ìµœì‹  ì •ë³´ê°€ ë°˜ì˜ë©ë‹ˆë‹¤.`
      }]
    };
  }

  // ì •ë¦¬ ì‘ì—…
  cleanup() {
    this.stopContinuousMonitoring();
    this.clearStatusCache();
    this.statusHistory = [];
    this.logger.info('ModelStatus ì •ë¦¬ ì™„ë£Œ');
  }
}
