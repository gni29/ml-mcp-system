#!/usr/bin/env node

import { Server } from '@modelcontextprotocol/sdk/server/index.js';
import { StdioServerTransport } from '@modelcontextprotocol/sdk/server/stdio.js';
import {
  CallToolRequestSchema,
  ListToolsRequestSchema,
} from '@modelcontextprotocol/sdk/types.js';

import { ModelManager } from './core/model-manager.js';
import { Router } from './core/router.js';
import { MainProcessor } from './core/main-processor.js';
import { ContextTracker } from './core/context-tracker.js';
import { Logger } from './utils/logger.js';
import fs from 'fs/promises';
import path from 'path';

class MLMCPServer {
  constructor() {
    this.server = new Server(
      {
        name: 'ml-mcp-high-performance',
        version: '1.0.0',
      },
      {
        capabilities: {
          tools: {},
        },
      }
    );

    this.logger = new Logger();
    this.modelManager = new ModelManager();
    this.router = new Router(this.modelManager);
    this.processor = new MainProcessor(this.modelManager);
    this.contextTracker = new ContextTracker();

    this.setupHandlers();
  }

  setupHandlers() {
    // ë„êµ¬ ëª©ë¡ ì œê³µ
    this.server.setRequestHandler(ListToolsRequestSchema, async () => {
      return {
        tools: await this.getAvailableTools()
      };
    });

    // ë„êµ¬ ì‹¤í–‰ ì²˜ë¦¬
    this.server.setRequestHandler(CallToolRequestSchema, async (request) => {
      const { name, arguments: args } = request.params;
      
      try {
        // ì»¨í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸
        this.contextTracker.updateContext(name, args);
        
        // íŠ¹ë³„í•œ ë„êµ¬ ì²˜ë¦¬
        if (name === 'general_query') {
          return await this.handleGeneralQuery(args);
        }
        
        // ë¼ìš°íŒ… ê²°ì •
        const routingDecision = await this.router.route(name, args);
        
        // ì‘ì—… ì‹¤í–‰
        const result = await this.executeTask(routingDecision, args);
        
        // ê²°ê³¼ ë°˜í™˜
        return result;
        
      } catch (error) {
        this.logger.error('Task execution failed:', error);
        return {
          content: [
            {
              type: 'text',
              text: `ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: ${error.message}`
            }
          ],
          isError: true
        };
      }
    });
  }

  async getAvailableTools() {
    const currentMode = this.contextTracker.getCurrentMode();
    const baseTools = [
      {
        name: 'general_query',
        description: 'ìì—°ì–´ ì§ˆë¬¸ ë° ëª…ë ¹ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤',
        inputSchema: {
          type: 'object',
          properties: {
            query: {
              type: 'string',
              description: 'ì‚¬ìš©ìì˜ ì§ˆë¬¸ì´ë‚˜ ëª…ë ¹'
            }
          },
          required: ['query']
        }
      },
      {
        name: 'mode_switch',
        description: 'ì‘ì—… ëª¨ë“œë¥¼ ì „í™˜í•©ë‹ˆë‹¤ (general/ml/coding)',
        inputSchema: {
          type: 'object',
          properties: {
            mode: {
              type: 'string',
              enum: ['general', 'ml', 'coding'],
              description: 'ì „í™˜í•  ëª¨ë“œ'
            }
          },
          required: ['mode']
        }
      },
      {
        name: 'system_status',
        description: 'ì‹œìŠ¤í…œ ë° ëª¨ë¸ ìƒíƒœë¥¼ í™•ì¸í•©ë‹ˆë‹¤',
        inputSchema: {
          type: 'object',
          properties: {},
          required: []
        }
      }
    ];

    // ëª¨ë“œì— ë”°ë¥¸ ì¶”ê°€ ë„êµ¬ë“¤
    if (currentMode === 'ml') {
      baseTools.push(
        {
          name: 'analyze_data',
          description: 'ë°ì´í„° ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤',
          inputSchema: {
            type: 'object',
            properties: {
              query: {
                type: 'string',
                description: 'ë¶„ì„ ìš”ì²­ ë‚´ìš©'
              },
              file_path: {
                type: 'string',
                description: 'ë¶„ì„í•  ë°ì´í„° íŒŒì¼ ê²½ë¡œ'
              },
              analysis_type: {
                type: 'string',
                enum: ['basic', 'advanced', 'full'],
                description: 'ë¶„ì„ ìˆ˜ì¤€',
                default: 'basic'
              },
              auto_detect_files: {
                type: 'boolean',
                description: 'íŒŒì¼ ìë™ ê°ì§€ ì—¬ë¶€',
                default: false
              }
            },
            required: ['query']
          }
        },
        {
          name: 'train_model',
          description: 'ML ëª¨ë¸ì„ í›ˆë ¨í•©ë‹ˆë‹¤',
          inputSchema: {
            type: 'object',
            properties: {
              query: {
                type: 'string',
                description: 'í›ˆë ¨ ìš”ì²­ ë‚´ìš©'
              },
              data_path: {
                type: 'string',
                description: 'í›ˆë ¨ ë°ì´í„° ê²½ë¡œ'
              },
              target_column: {
                type: 'string',
                description: 'íƒ€ê²Ÿ ë³€ìˆ˜ ì»¬ëŸ¼ëª…'
              },
              model_type: {
                type: 'string',
                enum: ['classification', 'regression', 'auto'],
                description: 'ëª¨ë¸ ìœ í˜•',
                default: 'auto'
              },
              auto_detect_files: {
                type: 'boolean',
                description: 'íŒŒì¼ ìë™ ê°ì§€ ì—¬ë¶€',
                default: false
              }
            },
            required: ['query']
          }
        },
        {
          name: 'visualize_data',
          description: 'ë°ì´í„° ì‹œê°í™”ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤',
          inputSchema: {
            type: 'object',
            properties: {
              query: {
                type: 'string',
                description: 'ì‹œê°í™” ìš”ì²­ ë‚´ìš©'
              },
              file_path: {
                type: 'string',
                description: 'ì‹œê°í™”í•  ë°ì´í„° íŒŒì¼ ê²½ë¡œ'
              },
              chart_type: {
                type: 'string',
                enum: ['auto', 'scatter', 'line', 'bar', 'histogram', 'heatmap'],
                description: 'ì°¨íŠ¸ ìœ í˜•',
                default: 'auto'
              },
              auto_detect_files: {
                type: 'boolean',
                description: 'íŒŒì¼ ìë™ ê°ì§€ ì—¬ë¶€',
                default: false
              }
            },
            required: ['query']
          }
        }
      );
    }

    return baseTools;
  }

  async handleGeneralQuery(args) {
    const { query } = args;
    
    // AI ëª¨ë¸ì„ ì‚¬ìš©í•´ ì‚¬ìš©ì ì˜ë„ ë¶„ì„
    const analysisPrompt = `ì‚¬ìš©ìê°€ "${query}"ë¼ê³  ë§í–ˆìŠµë‹ˆë‹¤.

ì´ê²ƒì´ ë‹¤ìŒ ì¤‘ ì–´ë–¤ ìœ í˜•ì˜ ìš”ì²­ì¸ì§€ ë¶„ì„í•´ì£¼ì„¸ìš”:
1. ë°ì´í„° ë¶„ì„ ìš”ì²­
2. ëª¨ë¸ í›ˆë ¨ ìš”ì²­  
3. ì‹œê°í™” ìš”ì²­
4. ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸
5. ëª¨ë“œ ë³€ê²½ ìš”ì²­
6. ì¼ë°˜ ëŒ€í™”

ë¶„ì„ ê²°ê³¼ë¥¼ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
{
  "intent": "ìš”ì²­ ìœ í˜•",
  "confidence": 0.0-1.0,
  "suggested_action": "ê¶Œì¥ í–‰ë™",
  "requires_files": true/false,
  "response": "ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì¤„ ì‘ë‹µ"
}`;

    try {
      const response = await this.modelManager.queryModel('router', analysisPrompt, {
        temperature: 0.1,
        max_tokens: 500
      });

      // JSON ì‘ë‹µ íŒŒì‹±
      let analysis;
      try {
        const jsonMatch = response.match(/\{[\s\S]*\}/);
        if (jsonMatch) {
          analysis = JSON.parse(jsonMatch[0]);
        }
      } catch (parseError) {
        this.logger.warn('ì˜ë„ ë¶„ì„ ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨:', parseError);
      }

      // ë¶„ì„ ê²°ê³¼ì— ë”°ë¥¸ ì²˜ë¦¬
      if (analysis) {
        // íŒŒì¼ì´ í•„ìš”í•œ ê²½ìš° ìë™ ê°ì§€
        if (analysis.requires_files) {
          const detectedFiles = await this.detectDataFiles();
          if (detectedFiles.length > 0) {
            analysis.response += `\n\nğŸ“ ê°ì§€ëœ ë°ì´í„° íŒŒì¼:\n${detectedFiles.map(f => `- ${f}`).join('\n')}`;
          }
        }

        return {
          content: [
            {
              type: 'text',
              text: analysis.response
            }
          ],
          metadata: {
            intent: analysis.intent,
            confidence: analysis.confidence,
            suggested_action: analysis.suggested_action
          }
        };
      }

      // íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ì‘ë‹µ
      return {
        content: [
          {
            type: 'text',
            text: response
          }
        ]
      };

    } catch (error) {
      this.logger.error('ì¼ë°˜ ì¿¼ë¦¬ ì²˜ë¦¬ ì‹¤íŒ¨:', error);
      return {
        content: [
          {
            type: 'text',
            text: 'ì£„ì†¡í•©ë‹ˆë‹¤. ìš”ì²­ì„ ì²˜ë¦¬í•˜ëŠ” ì¤‘ì— ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.'
          }
        ],
        isError: true
      };
    }
  }

  async detectDataFiles() {
    try {
      const files = await fs.readdir('./');
      const dataFiles = files.filter(file =>
        file.endsWith('.csv') ||
        file.endsWith('.xlsx') ||
        file.endsWith('.json') ||
        file.endsWith('.txt')
      );
      
      return dataFiles;
    } catch (error) {
      this.logger.error('íŒŒì¼ ê°ì§€ ì‹¤íŒ¨:', error);
      return [];
    }
  }

  async executeTask(routingDecision, args) {
    const { taskType, model, tools } = routingDecision;

    switch (taskType) {
      case 'simple':
        return await this.router.handleSimpleTask(args);
      
      case 'complex':
        return await this.processor.handleComplexTask(args, tools);
      
      case 'system':
        return await this.handleSystemTask(args);
      
      default:
        throw new Error(`Unknown task type: ${taskType}`);
    }
  }

  async handleSystemTask(args) {
    const { query, mode } = args;
    
    // ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸
    if (query && (query.includes('ìƒíƒœ') || query.includes('status'))) {
      return await this.getSystemStatus();
    }
    
    // ëª¨ë“œ ë³€ê²½
    if (mode) {
      await this.contextTracker.setMode(mode);
      return {
        content: [
          {
            type: 'text',
            text: `ğŸ”„ ëª¨ë“œê°€ '${mode}'ë¡œ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤.`
          }
        ]
      };
    }
    
    return {
      content: [
        {
          type: 'text',
          text: 'ì‹œìŠ¤í…œ ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.'
        }
      ]
    };
  }

  async getSystemStatus() {
    try {
      const modelStatus = await this.modelManager.getModelStatus();
      const contextStats = this.contextTracker.getUsageStats();
      
      const statusText = `ğŸ“Š ì‹œìŠ¤í…œ ìƒíƒœ:

ğŸ¤– ëª¨ë¸ ìƒíƒœ: ${Object.keys(modelStatus).length}ê°œ ëª¨ë¸ ì‹¤í–‰ ì¤‘
ğŸ”„ í˜„ì¬ ëª¨ë“œ: ${contextStats.currentMode}
ğŸ“ˆ ì²˜ë¦¬ëœ ì‘ì—…: ${contextStats.totalEntries}ê°œ
ğŸ’¾ í™œì„± ì„¸ì…˜: ${contextStats.activeSessions}ê°œ

ëª¨ë¸ ì„¸ë¶€ ì •ë³´:
${Object.entries(modelStatus).map(([type, info]) => 
  `- ${type}: ${info.name} (ë§ˆì§€ë§‰ ì‚¬ìš©: ${new Date(info.lastUsed).toLocaleString()})`
).join('\n')}`;

      return {
        content: [
          {
            type: 'text',
            text: statusText
          }
        ]
      };
    } catch (error) {
      this.logger.error('ì‹œìŠ¤í…œ ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨:', error);
      return {
        content: [
          {
            type: 'text',
            text: 'ì‹œìŠ¤í…œ ìƒíƒœë¥¼ í™•ì¸í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.'
          }
        ],
        isError: true
      };
    }
  }

  async run() {
    try {
      // ëª¨ë¸ ë§¤ë‹ˆì € ì´ˆê¸°í™”
      await this.modelManager.initialize();
      
      // ì»¨í…ìŠ¤íŠ¸ íŠ¸ë˜ì»¤ ì´ˆê¸°í™”
      await this.contextTracker.initialize();
      
      // MCP ì„œë²„ ì‹œì‘
      const transport = new StdioServerTransport();
      await this.server.connect(transport);
      
      this.logger.info('ML MCP ì„œë²„ê°€ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.');
      
    } catch (error) {
      this.logger.error('ì„œë²„ ì‹œì‘ ì‹¤íŒ¨:', error);
      process.exit(1);
    }
  }
}

// ì„œë²„ ì‹œì‘
const server = new MLMCPServer();
server.run().catch(console.error);
