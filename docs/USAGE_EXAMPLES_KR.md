# ML MCP ì‹œìŠ¤í…œ - ì‚¬ìš© ì˜ˆì œ ë° ì›Œí¬í”Œë¡œìš°

## ğŸ“– ê°œìš”

ì´ ë¬¸ì„œëŠ” ML MCP ì‹œìŠ¤í…œì˜ í¬ê´„ì ì¸ ì˜ˆì œì™€ ì‹¤ì œ ì›Œí¬í”Œë¡œìš°ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ê° ì˜ˆì œëŠ” ìƒ˜í”Œ ë°ì´í„°, ë‹¨ê³„ë³„ ì§€ì¹¨ ë° ì˜ˆìƒ ì¶œë ¥ì„ í¬í•¨í•©ë‹ˆë‹¤.

## ğŸ ë¹ ë¥¸ ì‹œì‘ ê°€ì´ë“œ

### í•„ìˆ˜ ì¡°ê±´
```bash
# 1. ì˜ì¡´ì„± ì„¤ì¹˜
npm install
pip install -r python/requirements.txt

# 2. MCP ì„œë²„ ì‹œì‘
npm run mcp:analysis
npm run mcp:ml
npm run mcp:visualization
```

### ì²« ë²ˆì§¸ ë¶„ì„ (5ë¶„)
```bash
# 1. ìƒ˜í”Œ ë°ì´í„° ì‚¬ìš©
cp data/sample_data.csv my_data.csv

# 2. ê¸°ë³¸ í†µê³„
echo '{"data_file": "my_data.csv"}' | python python/analyzers/basic/descriptive_stats.py

# 3. ì‹œê°í™” ìƒì„±
echo '{"data_file": "my_data.csv", "columns": ["age", "income"]}' | python python/visualization/2d/scatter.py
```

## ğŸ“Š ì‹¤ì œ ì›Œí¬í”Œë¡œìš°

### 1. ê³ ê° ë°ì´í„° ë¶„ì„ ì›Œí¬í”Œë¡œìš°

**ì‹œë‚˜ë¦¬ì˜¤**: ê³ ê° ì¸êµ¬í†µê³„ ë° êµ¬ë§¤ í–‰ë™ ë¶„ì„

**ìƒ˜í”Œ ë°ì´í„° êµ¬ì¡°**:
```csv
customer_id,age,income,education,spending_score,region
1001,25,35000,Bachelor,85,North
1002,45,75000,Master,45,South
1003,35,50000,Bachelor,75,East
...
```

#### ë‹¨ê³„ 1: ì´ˆê¸° ë°ì´í„° íƒìƒ‰
```bash
# ê¸°ë³¸ í†µê³„
echo '{
  "data_file": "customer_data.csv",
  "output_dir": "customer_analysis/step1_basics"
}' | python python/analyzers/basic/descriptive_stats.py
```

**ì˜ˆìƒ ì¶œë ¥**:
```json
{
  "success": true,
  "statistics": {
    "age": {"mean": 38.5, "std": 12.3, "min": 18, "max": 70},
    "income": {"mean": 52500, "std": 18200, "min": 20000, "max": 150000},
    "spending_score": {"mean": 60.2, "std": 25.8, "min": 1, "max": 99}
  }
}
```

#### ë‹¨ê³„ 2: ê²°ì¸¡ ë°ì´í„° ë¶„ì„
```bash
echo '{
  "data_file": "customer_data.csv",
  "output_dir": "customer_analysis/step2_missing"
}' | python python/analyzers/basic/missing_data.py
```

#### ë‹¨ê³„ 3: ìƒê´€ê´€ê³„ ë¶„ì„
```bash
echo '{
  "data_file": "customer_data.csv",
  "columns": ["age", "income", "spending_score"],
  "output_dir": "customer_analysis/step3_correlation"
}' | python python/analyzers/basic/correlation.py
```

#### ë‹¨ê³„ 4: ê³ ê° ì„¸ë¶„í™” (í´ëŸ¬ìŠ¤í„°ë§)
```bash
echo '{
  "data_file": "customer_data.csv",
  "feature_columns": ["age", "income", "spending_score"],
  "algorithms": ["kmeans", "hierarchical"],
  "n_clusters": 4,
  "output_dir": "customer_analysis/step4_segmentation"
}' | python python/ml/unsupervised/clustering.py
```

#### ë‹¨ê³„ 5: ì‹œê°í™” ëŒ€ì‹œë³´ë“œ
```bash
# ì‚°ì ë„ ë§¤íŠ¸ë¦­ìŠ¤
echo '{
  "data_file": "customer_data.csv",
  "x_column": "age",
  "y_column": "income",
  "color_column": "region",
  "size_column": "spending_score",
  "plot_types": ["2d", "matrix", "correlations"],
  "output_dir": "customer_analysis/step5_visuals"
}' | python python/visualizations/scatter_plots.py

# ì¸í„°ë™í‹°ë¸Œ ëŒ€ì‹œë³´ë“œ
echo '{
  "data_file": "customer_data.csv",
  "numeric_columns": ["age", "income", "spending_score"],
  "categorical_columns": ["education", "region"],
  "plot_types": ["plotly_dashboard", "plotly_3d"],
  "output_dir": "customer_analysis/step5_visuals"
}' | python python/visualizations/interactive_plots.py
```

### 2. ë§¤ì¶œ ì˜ˆì¸¡ ì›Œí¬í”Œë¡œìš°

**ì‹œë‚˜ë¦¬ì˜¤**: ê³¼ê±° ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì›”ë³„ ë§¤ì¶œ ì˜ˆì¸¡

**ìƒ˜í”Œ ë°ì´í„° êµ¬ì¡°**:
```csv
date,sales,marketing_spend,season,promotions,competitor_price
2023-01-01,125000,15000,Winter,2,99.99
2023-02-01,135000,18000,Winter,1,95.99
2023-03-01,142000,16000,Spring,3,98.99
...
```

#### ì™„ì „í•œ ì›Œí¬í”Œë¡œìš° ìŠ¤í¬ë¦½íŠ¸:
```bash
#!/bin/bash
# ë§¤ì¶œ ì˜ˆì¸¡ ì™„ì „ ì›Œí¬í”Œë¡œìš°

ANALYSIS_DIR="sales_forecast_$(date +%Y%m%d_%H%M%S)"
DATA_FILE="sales_data.csv"

echo "ğŸš€ ë§¤ì¶œ ì˜ˆì¸¡ ë¶„ì„ ì‹œì‘..."

# ë‹¨ê³„ 1: ë°ì´í„° í’ˆì§ˆ ê²€ì‚¬
echo "ğŸ“Š ë‹¨ê³„ 1: ë°ì´í„° í’ˆì§ˆ ë¶„ì„..."
echo '{
  "data_file": "'$DATA_FILE'",
  "output_dir": "'$ANALYSIS_DIR'/01_data_quality"
}' | python python/analyzers/basic/missing_data.py

# ë‹¨ê³„ 2: ì‹œê³„ì—´ ë¶„ì„
echo "ğŸ“ˆ ë‹¨ê³„ 2: ì‹œê³„ì—´ ì‹œê°í™”..."
echo '{
  "data_file": "'$DATA_FILE'",
  "date_column": "date",
  "value_columns": ["sales", "marketing_spend"],
  "plot_types": ["line", "seasonal_decompose", "rolling_stats"],
  "output_dir": "'$ANALYSIS_DIR'/02_timeseries"
}' | python python/visualizations/time_series_plots.py

# ë‹¨ê³„ 3: íŠ¹ì„± ê³µí•™
echo "ğŸ”§ ë‹¨ê³„ 3: íŠ¹ì„± ê³µí•™..."
echo '{
  "data_file": "'$DATA_FILE'",
  "target_column": "sales",
  "transformations": ["log", "polynomial"],
  "output_dir": "'$ANALYSIS_DIR'/03_features"
}' | python python/ml/preprocessing/feature_engineering.py

# ë‹¨ê³„ 4: ì˜ˆì¸¡ ëª¨ë¸
echo "ğŸ”® ë‹¨ê³„ 4: ì˜ˆì¸¡ ëª¨ë¸ êµ¬ì¶•..."
echo '{
  "data_file": "'$ANALYSIS_DIR'/03_features/engineered_data.csv",
  "date_column": "date",
  "value_column": "sales",
  "forecast_periods": 12,
  "models": ["arima", "exponential_smoothing", "linear_trend"],
  "output_dir": "'$ANALYSIS_DIR'/04_forecasting"
}' | python python/ml/time_series/forecasting.py

# ë‹¨ê³„ 5: ëª¨ë¸ í‰ê°€
echo "ğŸ“Š ë‹¨ê³„ 5: ëª¨ë¸ í‰ê°€..."
echo '{
  "model_files": ["'$ANALYSIS_DIR'/04_forecasting/arima_model.joblib",
                  "'$ANALYSIS_DIR'/04_forecasting/exp_smoothing_model.joblib"],
  "test_data_file": "'$DATA_FILE'",
  "target_column": "sales",
  "output_dir": "'$ANALYSIS_DIR'/05_evaluation"
}' | python python/ml/evaluation/model_evaluation.py

echo "âœ… ë¶„ì„ ì™„ë£Œ! ê²°ê³¼ ìœ„ì¹˜: $ANALYSIS_DIR"
```

### 3. ì˜ë£Œ ì§„ë‹¨ ë¶„ë¥˜

**ì‹œë‚˜ë¦¬ì˜¤**: ì˜ë£Œ ì§„ë‹¨ì„ ìœ„í•œ ë¶„ë¥˜ ëª¨ë¸ êµ¬ì¶•

**ìƒ˜í”Œ ë°ì´í„° êµ¬ì¡°**:
```csv
patient_id,age,gender,symptom1,symptom2,test_result1,test_result2,diagnosis
P001,45,M,1,0,15.2,Normal,Disease_A
P002,32,F,0,1,12.8,Abnormal,Healthy
P003,67,M,1,1,18.5,Abnormal,Disease_B
...
```

#### ê³ ê¸‰ ë¶„ë¥˜ ì›Œí¬í”Œë¡œìš°:
```bash
# 1. í¬ê´„ì  ë°ì´í„° ë¶„ì„
echo '{
  "data_file": "medical_data.csv",
  "output_dir": "medical_analysis/exploratory"
}' | python python/analyzers/basic/descriptive_stats.py

# 2. ì§„ë‹¨ë³„ ë¶„í¬ ë¶„ì„
echo '{
  "data_file": "medical_data.csv",
  "categorical_columns": ["diagnosis"],
  "numeric_columns": ["age", "test_result1"],
  "plot_types": ["box", "violin", "strip"],
  "output_dir": "medical_analysis/distributions"
}' | python python/visualizations/categorical_plots.py

# 3. íŠ¹ì„± ì„ íƒ ë° ê³µí•™
echo '{
  "data_file": "medical_data.csv",
  "target_column": "diagnosis",
  "techniques": ["selection", "scaling", "interaction"],
  "selection_method": "recursive",
  "output_dir": "medical_analysis/features"
}' | python python/ml/preprocessing/advanced_feature_engineering.py

# 4. ë‹¤ì¤‘ ì•Œê³ ë¦¬ì¦˜ ë¶„ë¥˜
echo '{
  "data_file": "medical_analysis/features/engineered_data.csv",
  "target_column": "diagnosis",
  "algorithms": ["logistic", "random_forest", "svm", "gradient_boosting"],
  "cross_validation": 10,
  "test_size": 0.2,
  "output_dir": "medical_analysis/models"
}' | python python/ml/supervised/classification/classification_trainer.py

# 5. í†µê³„ì  ê²€ì¦
echo '{
  "data_file": "medical_analysis/features/engineered_data.csv",
  "numeric_columns": ["age", "test_result1"],
  "target_column": "diagnosis",
  "plot_types": ["distribution", "qq", "confidence"],
  "output_dir": "medical_analysis/statistics"
}' | python python/visualizations/statistical_plots.py
```

### 4. ê¸ˆìœµ ë¦¬ìŠ¤í¬ í‰ê°€

**ì‹œë‚˜ë¦¬ì˜¤**: ê³ ê° ê¸ˆìœµ ë°ì´í„°ë¥¼ ì‚¬ìš©í•œ ëŒ€ì¶œ ì±„ë¬´ë¶ˆì´í–‰ ìœ„í—˜ í‰ê°€

**ìƒ˜í”Œ ë°ì´í„° êµ¬ì¡°**:
```csv
loan_id,age,income,credit_score,loan_amount,employment_years,debt_ratio,default
L001,28,45000,650,25000,3,0.35,0
L002,45,85000,750,50000,12,0.25,0
L003,35,35000,580,30000,2,0.65,1
...
```

#### ë¦¬ìŠ¤í¬ í‰ê°€ íŒŒì´í”„ë¼ì¸:
```python
# risk_assessment_pipeline.py
import subprocess
import json
from datetime import datetime

def run_analysis(params, script_path):
    """ë¶„ì„ ë„êµ¬ ì‹¤í–‰ì„ ìœ„í•œ í—¬í¼ í•¨ìˆ˜"""
    process = subprocess.run(
        ['python', script_path],
        input=json.dumps(params),
        text=True,
        capture_output=True
    )
    return json.loads(process.stdout)

def financial_risk_pipeline(data_file):
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_base = f"risk_assessment_{timestamp}"

    # ë‹¨ê³„ 1: ì´ìƒì¹˜ íƒì§€ (ì‚¬ê¸° ì§€í‘œ)
    print("ğŸ” ì´ìƒì¹˜ ë° ì´ìƒ í˜„ìƒ íƒì§€...")
    outlier_params = {
        "data_file": data_file,
        "methods": ["iqr", "isolation_forest", "lof"],
        "contamination": 0.05,
        "output_dir": f"{output_base}/01_outliers"
    }
    outliers = run_analysis(outlier_params, "python/analyzers/advanced/outlier_detection.py")

    # ë‹¨ê³„ 2: ìƒê´€ê´€ê³„ ë¶„ì„
    print("ğŸ“Š íŠ¹ì„± ìƒê´€ê´€ê³„ ë¶„ì„...")
    corr_params = {
        "data_file": data_file,
        "method": "spearman",  # ê¸ˆìœµ ë°ì´í„°ì— ë” ì í•©
        "min_correlation": 0.3,
        "output_dir": f"{output_base}/02_correlations"
    }
    correlations = run_analysis(corr_params, "python/analyzers/basic/correlation.py")

    # ë‹¨ê³„ 3: ë¦¬ìŠ¤í¬ íŒ©í„° ê³µí•™
    print("ğŸ”§ ë¦¬ìŠ¤í¬ íŒ©í„° ê³µí•™...")
    feature_params = {
        "data_file": data_file,
        "target_column": "default",
        "transformations": ["log", "interaction"],
        "output_dir": f"{output_base}/03_features"
    }
    features = run_analysis(feature_params, "python/ml/preprocessing/feature_engineering.py")

    # ë‹¨ê³„ 4: ë¶ˆê· í˜• ë°ì´í„° ì²˜ë¦¬ì™€ ëª¨ë¸ í›ˆë ¨
    print("ğŸ¤– ë¦¬ìŠ¤í¬ ëª¨ë¸ í›ˆë ¨...")
    model_params = {
        "data_file": f"{output_base}/03_features/engineered_data.csv",
        "target_column": "default",
        "algorithms": ["logistic", "random_forest", "gradient_boosting"],
        "cross_validation": 5,
        "class_weight": "balanced",  # ë¶ˆê· í˜• í´ë˜ìŠ¤ ì²˜ë¦¬
        "output_dir": f"{output_base}/04_models"
    }
    models = run_analysis(model_params, "python/ml/supervised/classification/classification_trainer.py")

    # ë‹¨ê³„ 5: ë¦¬ìŠ¤í¬ ì‹œê°í™”
    print("ğŸ“ˆ ë¦¬ìŠ¤í¬ ì‹œê°í™” ìƒì„±...")
    viz_params = {
        "data_file": data_file,
        "numeric_columns": ["age", "income", "credit_score", "debt_ratio"],
        "categorical_columns": ["default"],
        "plot_types": ["plotly_scatter", "plotly_heatmap", "plotly_dashboard"],
        "output_dir": f"{output_base}/05_visualizations"
    }
    visualizations = run_analysis(viz_params, "python/visualizations/interactive_plots.py")

    print(f"âœ… ë¦¬ìŠ¤í¬ í‰ê°€ ì™„ë£Œ! ê²°ê³¼ ìœ„ì¹˜: {output_base}")
    return {
        "analysis_id": output_base,
        "outliers_detected": len(outliers.get("consensus_outliers", [])),
        "best_model": models.get("best_model", {}),
        "key_risk_factors": correlations.get("significant_correlations", [])[:5]
    }

# ì‚¬ìš©ë²•
if __name__ == "__main__":
    result = financial_risk_pipeline("loan_data.csv")
    print(json.dumps(result, indent=2))
```

## ğŸ¯ íŠ¹í™” ì‚¬ìš© ì‚¬ë¡€

### A. ë¶€ë™ì‚° ê°€ê²© ì˜ˆì¸¡

```bash
# ì™„ì „í•œ ë¶€ë™ì‚° ë¶„ì„
echo '{
  "data_file": "real_estate.csv",
  "target_column": "price",
  "feature_columns": ["sqft", "bedrooms", "bathrooms", "age", "location_score"],
  "algorithms": ["linear", "ridge", "random_forest"],
  "output_dir": "real_estate_analysis"
}' | python python/ml/supervised/regression/regression_trainer.py
```

### B. ë§ˆì¼€íŒ… ìº í˜ì¸ ìµœì í™”

```bash
# A/B í…ŒìŠ¤íŠ¸ ë¶„ì„
echo '{
  "data_file": "campaign_data.csv",
  "categorical_columns": ["campaign_type", "customer_segment"],
  "numeric_columns": ["conversion_rate", "cost_per_click", "revenue"],
  "plot_types": ["bar", "box", "heatmap"],
  "output_dir": "campaign_analysis"
}' | python python/visualizations/categorical_plots.py
```

### C. í’ˆì§ˆ ê´€ë¦¬ ë¶„ì„

```bash
# ì œì¡° í’ˆì§ˆ ë¶„ì„
echo '{
  "data_file": "production_data.csv",
  "columns": ["temperature", "pressure", "speed", "quality_score"],
  "methods": ["iqr", "zscore"],
  "output_dir": "quality_control"
}' | python python/analyzers/advanced/outlier_detection.py
```

## ğŸ“‹ ëª¨ë²” ì‚¬ë¡€ ë° íŒ

### 1. ë°ì´í„° ì¤€ë¹„ ì²´í¬ë¦¬ìŠ¤íŠ¸
```bash
# ë¶„ì„ ì „ì— í•­ìƒ í™•ì¸:
echo '{
  "data_file": "your_data.csv"
}' | python python/analyzers/basic/missing_data.py

# ì •ë¦¬ ë° ê²€ì¦
echo '{
  "data_file": "your_data.csv",
  "strategy": "analyze"
}' | python python/analyzers/basic/missing_data.py
```

### 2. ì ì§„ì  ë¶„ì„ ì „ëµ

**1ë‹¨ê³„: íƒìƒ‰** (5-10ë¶„)
- ê¸°ë³¸ í†µê³„
- ê²°ì¸¡ ë°ì´í„° ë¶„ì„
- ë¶„í¬ í”Œë¡¯

**2ë‹¨ê³„: ì¡°ì‚¬** (15-30ë¶„)
- ìƒê´€ê´€ê³„ ë¶„ì„
- ì´ìƒì¹˜ íƒì§€
- ë²”ì£¼í˜• ë¶„ì„

**3ë‹¨ê³„: ëª¨ë¸ë§** (30-60ë¶„)
- íŠ¹ì„± ê³µí•™
- ëª¨ë¸ í›ˆë ¨
- ëª¨ë¸ í‰ê°€

**4ë‹¨ê³„: ê²€ì¦** (15-30ë¶„)
- í†µê³„ì  í…ŒìŠ¤íŠ¸
- ì”ì°¨ ë¶„ì„
- êµì°¨ ê²€ì¦

### 3. ì¶œë ¥ ì¡°ì§í™”

```
project_analysis_YYYYMMDD_HHMMSS/
â”œâ”€â”€ 01_exploration/
â”‚   â”œâ”€â”€ basic_stats.json
â”‚   â”œâ”€â”€ distributions.png
â”‚   â””â”€â”€ missing_data.json
â”œâ”€â”€ 02_investigation/
â”‚   â”œâ”€â”€ correlations.png
â”‚   â”œâ”€â”€ outliers.json
â”‚   â””â”€â”€ categorical_analysis.png
â”œâ”€â”€ 03_modeling/
â”‚   â”œâ”€â”€ features/
â”‚   â”œâ”€â”€ models/
â”‚   â””â”€â”€ evaluation/
â”œâ”€â”€ 04_validation/
â”‚   â”œâ”€â”€ statistical_tests.json
â”‚   â””â”€â”€ residual_plots.png
â””â”€â”€ final_report.html
```

### 4. ì‚°ì—…ë³„ ì¼ë°˜ì ì¸ ì›Œí¬í”Œë¡œìš°

#### ì˜ë£Œ ë¶„ì„
```bash
# í™˜ì ê²°ê³¼ ì˜ˆì¸¡
1. missing_data.py â†’ í™˜ì ê¸°ë¡ ì •ë¦¬
2. correlation.py â†’ ì¦ìƒ ê´€ê³„ ì°¾ê¸°
3. classification.py â†’ ê²°ê³¼ ì˜ˆì¸¡
4. statistical_plots.py â†’ ê²°ê³¼ ê²€ì¦
```

#### ê¸ˆìœµ ì„œë¹„ìŠ¤
```bash
# ì‹ ìš© ë¦¬ìŠ¤í¬ í‰ê°€
1. outlier_detection.py â†’ ì‚¬ê¸° íƒì§€
2. feature_engineering.py â†’ ë¦¬ìŠ¤í¬ íŒ©í„°
3. classification.py â†’ ì±„ë¬´ë¶ˆì´í–‰ ì˜ˆì¸¡
4. interactive_plots.py â†’ ë¦¬ìŠ¤í¬ ëŒ€ì‹œë³´ë“œ
```

#### ë¦¬í…Œì¼ ë¶„ì„
```bash
# ê³ ê° ì„¸ë¶„í™”
1. descriptive_stats.py â†’ ê³ ê° ì¸êµ¬í†µê³„
2. clustering.py â†’ ê³ ê° ì„¸ë¶„í™”
3. scatter_plots.py â†’ ì„¸ê·¸ë¨¼íŠ¸ ì‹œê°í™”
4. forecasting.py â†’ ìˆ˜ìš” ì˜ˆì¸¡
```

#### ì œì¡°ì—…
```bash
# í’ˆì§ˆ ê´€ë¦¬
1. distribution.py â†’ í”„ë¡œì„¸ìŠ¤ ì•ˆì •ì„±
2. outlier_detection.py â†’ ê²°í•¨ íƒì§€
3. time_series_plots.py â†’ íŠ¸ë Œë“œ ë¶„ì„
4. regression.py â†’ í’ˆì§ˆ ì˜ˆì¸¡
```

## ğŸ”§ í†µí•© ì˜ˆì œ

### Jupyter Notebookê³¼ í•¨ê»˜
```python
import subprocess
import json
import pandas as pd

def run_mcp_tool(tool_script, params):
    """Jupyterì—ì„œ MCP ë„êµ¬ ì‹¤í–‰"""
    result = subprocess.run(
        ['python', tool_script],
        input=json.dumps(params),
        text=True,
        capture_output=True
    )
    return json.loads(result.stdout)

# ì‚¬ìš© ì˜ˆì œ
params = {
    "data_file": "data.csv",
    "columns": ["feature1", "feature2"]
}
result = run_mcp_tool("python/analyzers/basic/correlation.py", params)
print(result)
```

### R í†µí•©
```r
# MCP ë„êµ¬ìš© R ë˜í¼
library(jsonlite)

run_mcp_analysis <- function(script_path, params) {
  params_json <- toJSON(params, auto_unbox = TRUE)
  result <- system2("python",
                   args = script_path,
                   input = params_json,
                   stdout = TRUE)
  fromJSON(result)
}

# ì‚¬ìš©ë²•
params <- list(data_file = "data.csv", columns = c("x", "y"))
result <- run_mcp_analysis("python/analyzers/basic/correlation.py", params)
```

### ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ê³¼ í•¨ê»˜
```javascript
// Node.js ì›¹ ì„œë¹„ìŠ¤ í†µí•©
const { spawn } = require('child_process');

async function runMCPAnalysis(scriptPath, params) {
  return new Promise((resolve, reject) => {
    const python = spawn('python', [scriptPath]);

    python.stdin.write(JSON.stringify(params));
    python.stdin.end();

    let result = '';
    python.stdout.on('data', (data) => {
      result += data;
    });

    python.on('close', (code) => {
      if (code === 0) {
        resolve(JSON.parse(result));
      } else {
        reject(new Error('ë¶„ì„ ì‹¤íŒ¨'));
      }
    });
  });
}

// Express.jsì—ì„œ ì‚¬ìš©
app.post('/api/analyze', async (req, res) => {
  try {
    const result = await runMCPAnalysis(
      'python/analyzers/basic/descriptive_stats.py',
      req.body
    );
    res.json(result);
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});
```

## ğŸš¨ ë¬¸ì œ í•´ê²° ê°€ì´ë“œ

### ì¼ë°˜ì ì¸ ë¬¸ì œ ë° í•´ê²°ì±…

**1. "ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŒ" ì˜¤ë¥˜**
```bash
# í•´ê²°ì±…: Python ê²½ë¡œ í™•ì¸
export PYTHONPATH="${PYTHONPATH}:$(pwd)/python"
pip install -r python/requirements.txt
```

**2. "íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ" ì˜¤ë¥˜**
```bash
# í•´ê²°ì±…: ì ˆëŒ€ ê²½ë¡œ ì‚¬ìš©
echo '{
  "data_file": "/full/path/to/data.csv"
}' | python python/analyzers/basic/descriptive_stats.py
```

**3. ëŒ€ìš©ëŸ‰ ë°ì´í„°ì…‹ì˜ ë©”ëª¨ë¦¬ ì˜¤ë¥˜**
```bash
# í•´ê²°ì±…: ìƒ˜í”Œë§ ì‚¬ìš©
echo '{
  "data_file": "large_data.csv",
  "sample_size": 10000
}' | python python/analyzers/basic/descriptive_stats.py
```

**4. ê¶Œí•œ ì˜¤ë¥˜**
```bash
# í•´ê²°ì±…: ë””ë ‰í† ë¦¬ ê¶Œí•œ í™•ì¸
chmod 755 output_directory
mkdir -p output_directory
```

## ğŸ“ˆ ì„±ëŠ¥ ìµœì í™”

### ëŒ€ìš©ëŸ‰ ë°ì´í„°ì…‹ì˜ ê²½ìš°
1. **ì²­í‚¹ ì‚¬ìš©**: ë” ì‘ì€ ë°°ì¹˜ë¡œ ë°ì´í„° ì²˜ë¦¬
2. **ë¨¼ì € ìƒ˜í”Œë§**: íƒìƒ‰ì„ ìœ„í•´ ëŒ€í‘œ ìƒ˜í”Œ ì‚¬ìš©
3. **ë©”ëª¨ë¦¬ ìµœì í™”**: íŒŒì¼ì„ ë‹«ê³  ë³€ìˆ˜ë¥¼ ì •ë¦¬
4. **ë³‘ë ¬ ì²˜ë¦¬**: ê°€ëŠ¥í•œ ê²½ìš° ë‹¤ì¤‘ ì½”ì–´ ì‚¬ìš©

### í”„ë¡œë•ì…˜ ì‚¬ìš©
1. **ê²°ê³¼ ìºì‹œ**: ì¤‘ê°„ ê²°ê³¼ ì €ì¥
2. **ì…ë ¥ ê²€ì¦**: ì²˜ë¦¬ ì „ ë°ì´í„° í’ˆì§ˆ í™•ì¸
3. **ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§**: ë©”ëª¨ë¦¬ ë° CPU ì‚¬ìš©ëŸ‰ ì¶”ì 
4. **ë¡œê·¸ ì‘ì—…**: ë””ë²„ê¹…ì„ ìœ„í•œ ìƒì„¸ ë¡œê·¸ ìœ ì§€

---

*ë” ë§ì€ ì˜ˆì œì™€ ê³ ê¸‰ ì‚¬ìš© íŒ¨í„´ì€ [ê°œë°œì ê°€ì´ë“œ](DEVELOPER_GUIDE_KR.md) ë° [API ë ˆí¼ëŸ°ìŠ¤](API_REFERENCE_KR.md)ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.*