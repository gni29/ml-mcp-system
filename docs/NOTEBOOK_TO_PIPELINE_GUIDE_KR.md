# Jupyter ë…¸íŠ¸ë¶ì„ ML íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ ë³€í™˜ ê°€ì´ë“œ

íƒìƒ‰ì  Jupyter ë…¸íŠ¸ë¶ì„ í”„ë¡œë•ì…˜ ì¤€ë¹„ëœ ML íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ ìë™ ë³€í™˜í•©ë‹ˆë‹¤.

---

## ğŸ¯ ê°œìš”

**ë…¸íŠ¸ë¶-íŒŒì´í”„ë¼ì¸** ë³€í™˜ê¸°ëŠ” Jupyter ë…¸íŠ¸ë¶ì„ ë¶„ì„í•˜ì—¬ ë‹¤ìŒì„ ì¶”ì¶œí•©ë‹ˆë‹¤:
- ë°ì´í„° ë¡œë”© ì½”ë“œ
- ì „ì²˜ë¦¬ ë‹¨ê³„
- íŠ¹ì§• ì—”ì§€ë‹ˆì–´ë§
- ëª¨ë¸ í•™ìŠµ
- í‰ê°€ ë©”íŠ¸ë¦­
- ì˜ˆì¸¡ ë¡œì§

ê·¸ë¦¬ê³  ë‹¤ìŒì„ ìƒì„±í•©ë‹ˆë‹¤:
- âœ… êµ¬ì¡°í™”ëœ Python íŒŒì´í”„ë¼ì¸ ìŠ¤í¬ë¦½íŠ¸
- âœ… ì„¤ì • íŒŒì¼ (JSON)
- âœ… í…ŒìŠ¤íŠ¸ íŒŒì¼ (ì„ íƒì‚¬í•­)
- âœ… CLI ì¸í„°í˜ì´ìŠ¤
- âœ… ì‚¬ìš©í•˜ê¸° ì‰¬ìš´ MLPipeline í´ë˜ìŠ¤

---

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### Pythonìœ¼ë¡œ ì§ì ‘ ì‚¬ìš©

```python
from python.ml.pipeline.notebook_to_pipeline import NotebookToPipeline

# ë³€í™˜ê¸° ì´ˆê¸°í™”
transformer = NotebookToPipeline('analysis.ipynb', framework='sklearn')

# ë…¸íŠ¸ë¶ íŒŒì‹±
parse_result = transformer.parse_notebook()
print(f"{parse_result['total_cells']}ê°œì˜ ì½”ë“œ ì…€ ë°œê²¬")
print(f"ê°ì§€ëœ í”„ë ˆì„ì›Œí¬: {parse_result['framework']}")

# íŒŒì´í”„ë¼ì¸ ìƒì„±
files = transformer.generate_pipeline(
    output_path='ml_pipeline.py',
    include_tests=True,
    include_config=True
)

print(f"ìƒì„±ë¨: {files}")

# ìš”ì•½ ì¶œë ¥
print(transformer.generate_summary())
```

### CLI ì‚¬ìš©

```bash
# ê¸°ë³¸ ì‚¬ìš©ë²•
python -m python.ml.pipeline.notebook_to_pipeline \
  --notebook analysis.ipynb \
  --output ml_pipeline.py

# í…ŒìŠ¤íŠ¸ ë° ìš”ì•½ í¬í•¨
python -m python.ml.pipeline.notebook_to_pipeline \
  --notebook analysis.ipynb \
  --output ml_pipeline.py \
  --include-tests \
  --summary

# í”„ë ˆì„ì›Œí¬ ì§€ì •
python -m python.ml.pipeline.notebook_to_pipeline \
  --notebook pytorch_model.ipynb \
  --output pytorch_pipeline.py \
  --framework pytorch
```

### MCP ë„êµ¬ ì‚¬ìš©

```javascript
await mcp.call('notebook_to_pipeline', {
  notebook_path: 'experiments/analysis.ipynb',
  output_path: 'pipelines/ml_pipeline.py',
  framework: 'sklearn',
  include_tests: true,
  include_config: true,
  show_summary: true
});
```

---

## ğŸ“‹ ìƒì„±ë˜ëŠ” íŒŒì¼

### 1. ë©”ì¸ íŒŒì´í”„ë¼ì¸ íŒŒì¼ (`ml_pipeline.py`)

```python
"""
ML íŒŒì´í”„ë¼ì¸
Jupyter ë…¸íŠ¸ë¶ì—ì„œ ìƒì„±: analysis.ipynb
"""

import pandas as pd
import numpy as np
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler

# ì„¤ì •
CONFIG = {
    'data': {'input_path': 'data/input', 'test_size': 0.2},
    'preprocessing': {'handle_missing': True, 'scale_features': True},
    'model': {'save_path': 'models'}
}

def load_data(config):
    """ë°ì´í„° ë¡œë“œ ë° ì¤€ë¹„"""
    # ë…¸íŠ¸ë¶ì˜ ë°ì´í„° ë¡œë”© ì½”ë“œê°€ ì—¬ê¸°ì— ë“¤ì–´ê°‘ë‹ˆë‹¤
    pass

def preprocess_data(X, y, config):
    """íŠ¹ì§• ì „ì²˜ë¦¬"""
    # ë…¸íŠ¸ë¶ì˜ ì „ì²˜ë¦¬ ì½”ë“œê°€ ì—¬ê¸°ì— ë“¤ì–´ê°‘ë‹ˆë‹¤
    pass

def train_model(X_train, y_train, config):
    """ML ëª¨ë¸ í•™ìŠµ"""
    # ë…¸íŠ¸ë¶ì˜ í•™ìŠµ ì½”ë“œê°€ ì—¬ê¸°ì— ë“¤ì–´ê°‘ë‹ˆë‹¤
    pass

def evaluate_model(model, X_test, y_test):
    """ëª¨ë¸ ì„±ëŠ¥ í‰ê°€"""
    # ë…¸íŠ¸ë¶ì˜ í‰ê°€ ì½”ë“œê°€ ì—¬ê¸°ì— ë“¤ì–´ê°‘ë‹ˆë‹¤
    pass

class MLPipeline:
    """ì™„ì „í•œ ML íŒŒì´í”„ë¼ì¸"""

    def __init__(self, config=None):
        self.config = config or CONFIG
        self.model = None

    def fit(self, X, y):
        """ì™„ì „í•œ íŒŒì´í”„ë¼ì¸ í•™ìŠµ"""
        X_processed, y_processed = preprocess_data(X, y, self.config)
        self.model = train_model(X_processed, y_processed, self.config)
        return self

    def predict(self, X):
        """ì˜ˆì¸¡ ìˆ˜í–‰"""
        X_processed, _ = preprocess_data(X, None, self.config)
        return self.model.predict(X_processed)

    def save(self, path):
        """íŒŒì´í”„ë¼ì¸ ì €ì¥"""
        import joblib
        joblib.dump(self, path)

    @classmethod
    def load(cls, path):
        """íŒŒì´í”„ë¼ì¸ ë¡œë“œ"""
        import joblib
        return joblib.load(path)

# CLI ì¸í„°í˜ì´ìŠ¤
if __name__ == '__main__':
    import argparse
    # ì™„ì „í•œ CLI êµ¬í˜„...
```

### 2. ì„¤ì • íŒŒì¼ (`ml_pipeline_config.json`)

```json
{
  "notebook": "analysis.ipynb",
  "generated": "2025-10-01T10:30:00",
  "framework": "sklearn",
  "dependencies": ["pandas", "numpy", "scikit-learn"],
  "components": {
    "data_loading": true,
    "preprocessing": true,
    "feature_engineering": true,
    "model_training": true,
    "model_evaluation": true
  },
  "pipeline_config": {
    "data": {
      "input_path": "data/input.csv",
      "test_size": 0.2,
      "random_state": 42
    },
    "preprocessing": {
      "handle_missing": true,
      "scale_features": true
    },
    "model": {
      "save_path": "models/model.pkl"
    }
  }
}
```

### 3. í…ŒìŠ¤íŠ¸ íŒŒì¼ (`test_ml_pipeline.py`)

```python
"""ML íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸"""

import unittest
import pandas as pd
import numpy as np
from ml_pipeline import MLPipeline

class TestMLPipeline(unittest.TestCase):
    """ML íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸"""

    def setUp(self):
        self.pipeline = MLPipeline()
        # ìƒ˜í”Œ ë°ì´í„° ìƒì„±
        self.X_train = pd.DataFrame({
            'feature1': np.random.randn(100),
            'feature2': np.random.randn(100)
        })
        self.y_train = pd.Series(np.random.randint(0, 2, 100))

    def test_pipeline_fit(self):
        """íŒŒì´í”„ë¼ì¸ í•™ìŠµ í…ŒìŠ¤íŠ¸"""
        self.pipeline.fit(self.X_train, self.y_train)
        self.assertIsNotNone(self.pipeline.model)

    def test_pipeline_predict(self):
        """íŒŒì´í”„ë¼ì¸ ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸"""
        self.pipeline.fit(self.X_train, self.y_train)
        predictions = self.pipeline.predict(self.X_train)
        self.assertEqual(len(predictions), len(self.X_train))

if __name__ == '__main__':
    unittest.main()
```

---

## ğŸ’¡ ì‚¬ìš© ì˜ˆì œ

### ì˜ˆì œ 1: ëª¨ë¸ í•™ìŠµ ë° ì €ì¥

```bash
# ëª¨ë¸ í•™ìŠµ
python ml_pipeline.py --train data/train.csv --model-path model.pkl

# ì»¤ìŠ¤í…€ ì„¤ì • ì‚¬ìš©
python ml_pipeline.py --train data/train.csv --config my_config.json --model-path model.pkl
```

### ì˜ˆì œ 2: ì˜ˆì¸¡ ìˆ˜í–‰

```bash
# ì˜ˆì¸¡ ìˆ˜í–‰
python ml_pipeline.py --predict data/new_data.csv --model-path model.pkl
```

### ì˜ˆì œ 3: í•™ìŠµ ë° í‰ê°€

```bash
# í•œ ë²ˆì— í•™ìŠµ ë° í‰ê°€
python ml_pipeline.py \
  --train data/train.csv \
  --test data/test.csv \
  --model-path model.pkl
```

### ì˜ˆì œ 4: ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ ì‚¬ìš©

```python
from ml_pipeline import MLPipeline
import pandas as pd

# ë°ì´í„° ë¡œë“œ
X_train = pd.read_csv('data/train.csv')
y_train = X_train['target']
X_train = X_train.drop('target', axis=1)

# íŒŒì´í”„ë¼ì¸ ìƒì„± ë° í•™ìŠµ
pipeline = MLPipeline()
pipeline.fit(X_train, y_train)

# ëª¨ë¸ ì €ì¥
pipeline.save('models/my_model.pkl')

# ë‚˜ì¤‘ì—: ë¡œë“œ ë° ì˜ˆì¸¡
pipeline = MLPipeline.load('models/my_model.pkl')
X_new = pd.read_csv('data/new_data.csv')
predictions = pipeline.predict(X_new)
```

---

## ğŸ” ì¶”ì¶œë˜ëŠ” ë‚´ìš©

ë³€í™˜ê¸°ëŠ” ìë™ìœ¼ë¡œ ë‹¤ìŒì„ ì‹ë³„í•˜ê³  ì¶”ì¶œí•©ë‹ˆë‹¤:

### 1. ë°ì´í„° ë¡œë”©
```python
# ë‹¤ìŒê³¼ ê°™ì€ íŒ¨í„´ ê°ì§€:
df = pd.read_csv('data.csv')
df = pd.read_excel('data.xlsx')
data = np.load('data.npy')
```

### 2. ì „ì²˜ë¦¬
```python
# ë‹¤ìŒê³¼ ê°™ì€ íŒ¨í„´ ê°ì§€:
df.fillna(df.mean())
df.dropna()
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
```

### 3. íŠ¹ì§• ì—”ì§€ë‹ˆì–´ë§
```python
# ë‹¤ìŒê³¼ ê°™ì€ íŒ¨í„´ ê°ì§€:
selector = SelectKBest(k=10)
X_selected = selector.fit_transform(X, y)
pca = PCA(n_components=5)
X_pca = pca.fit_transform(X)
```

### 4. ëª¨ë¸ í•™ìŠµ
```python
# ë‹¤ìŒê³¼ ê°™ì€ íŒ¨í„´ ê°ì§€:
model = RandomForestClassifier()
model.fit(X_train, y_train)
model = XGBClassifier()
model.fit(X_train, y_train)
```

### 5. í‰ê°€
```python
# ë‹¤ìŒê³¼ ê°™ì€ íŒ¨í„´ ê°ì§€:
accuracy = accuracy_score(y_test, y_pred)
print(classification_report(y_test, y_pred))
confusion_matrix(y_test, y_pred)
```

---

## âš™ï¸ ì„¤ì • ì˜µì…˜

### í”„ë ˆì„ì›Œí¬ ê°ì§€

ë³€í™˜ê¸°ëŠ” ì‚¬ìš©ëœ ML í”„ë ˆì„ì›Œí¬ë¥¼ ìë™ ê°ì§€í•©ë‹ˆë‹¤:
- **sklearn**: scikit-learn ëª¨ë¸
- **pytorch**: PyTorch ëª¨ë¸
- **tensorflow**: TensorFlow/Keras ëª¨ë¸
- **xgboost**: XGBoost ëª¨ë¸
- **lightgbm**: LightGBM ëª¨ë¸

ìˆ˜ë™ìœ¼ë¡œ ì§€ì •í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤:
```python
transformer = NotebookToPipeline('notebook.ipynb', framework='sklearn')
```

### ìƒì„± ì˜µì…˜

```python
files = transformer.generate_pipeline(
    output_path='pipeline.py',       # ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
    include_tests=True,               # í…ŒìŠ¤íŠ¸ íŒŒì¼ ìƒì„±
    include_config=True               # ì„¤ì • íŒŒì¼ ìƒì„±
)
```

---

## ğŸ“Š ë³€í™˜ ìš”ì•½

ë³€í™˜ í›„ ìƒì„¸í•œ ìš”ì•½ì„ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```
ë…¸íŠ¸ë¶-íŒŒì´í”„ë¼ì¸ ë³€í™˜ ìš”ì•½
==================================================

ë…¸íŠ¸ë¶: analysis.ipynb
í”„ë ˆì„ì›Œí¬: sklearn
ì´ ì…€ ìˆ˜: 25

ì¶”ì¶œëœ ì»´í¬ë„ŒíŠ¸:
  - Imports: 5
  - ë°ì´í„° ë¡œë”©: 2
  - ì „ì²˜ë¦¬: 4
  - íŠ¹ì§• ì—”ì§€ë‹ˆì–´ë§: 2
  - ëª¨ë¸ í•™ìŠµ: 3
  - ëª¨ë¸ í‰ê°€: 2
  - ì˜ˆì¸¡: 1
  - ì‹œê°í™”: 4
  - ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜: 2

ì¢…ì†ì„±: numpy, pandas, scikit-learn, matplotlib

ìƒì„±ëœ íŒŒì´í”„ë¼ì¸ êµ¬ì¡°:
  âœ“ ë°ì´í„° ë¡œë”© í•¨ìˆ˜
  âœ“ ì „ì²˜ë¦¬ í•¨ìˆ˜
  âœ“ íŠ¹ì§• ì—”ì§€ë‹ˆì–´ë§ í•¨ìˆ˜
  âœ“ í•™ìŠµ í•¨ìˆ˜
  âœ“ í‰ê°€ í•¨ìˆ˜
  âœ“ ì˜ˆì¸¡ í•¨ìˆ˜
  âœ“ íŒŒì´í”„ë¼ì¸ í´ë˜ìŠ¤
  âœ“ CLI ì¸í„°í˜ì´ìŠ¤
```

---

## ğŸ¯ ëª¨ë²” ì‚¬ë¡€

### 1. ë…¸íŠ¸ë¶ êµ¬ì„±

ìµœìƒì˜ ê²°ê³¼ë¥¼ ìœ„í•´ ëª…í™•í•œ ì„¹ì…˜ìœ¼ë¡œ ë…¸íŠ¸ë¶ì„ êµ¬ì„±í•˜ì„¸ìš”:
- ë°ì´í„° ë¡œë”©
- íƒìƒ‰ì  ë°ì´í„° ë¶„ì„ (EDA)
- ì „ì²˜ë¦¬
- íŠ¹ì§• ì—”ì§€ë‹ˆì–´ë§
- ëª¨ë¸ í•™ìŠµ
- í‰ê°€
- ì˜ˆì¸¡

### 2. ì„¤ëª…ì ì¸ ë³€ìˆ˜ëª… ì‚¬ìš©

```python
# ì¢‹ìŒ
X_train, X_test, y_train, y_test = train_test_split(X, y)

# í”¼í•˜ê¸°
a, b, c, d = train_test_split(X, y)
```

### 3. í•¨ìˆ˜ë¥¼ ëª¨ë“ˆí™”í•˜ì—¬ ìœ ì§€

```python
# ì¢‹ìŒ - ì¶”ì¶œí•˜ê¸° ì‰¬ì›€
def preprocess_data(df):
    df = df.fillna(df.mean())
    return df

# í”¼í•˜ê¸° - ì¶”ì¶œí•˜ê¸° ì–´ë ¤ì›€
df = df.fillna(df.mean())  # ë…¸íŠ¸ë¶ ì „ì²´ì— í©ì–´ì§
```

### 4. ìƒì„±ëœ ì½”ë“œ ê²€í† 

í•­ìƒ ìƒì„±ëœ íŒŒì´í”„ë¼ì¸ì„ ê²€í† í•˜ê³  í…ŒìŠ¤íŠ¸í•˜ì„¸ìš”:
```bash
# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
python test_ml_pipeline.py

# ìƒ˜í”Œ ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸
python ml_pipeline.py --train sample_data.csv --test sample_test.csv
```

---

## ğŸ”§ ê³ ê¸‰ ì‚¬ìš©ë²•

### ì»¤ìŠ¤í…€ íŒŒì´í”„ë¼ì¸ í…œí”Œë¦¿

ë³€í™˜ê¸°ë¥¼ í™•ì¥í•˜ì—¬ ì»¤ìŠ¤í…€ í…œí”Œë¦¿ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```python
class CustomNotebookToPipeline(NotebookToPipeline):
    def _generate_pipeline_class(self):
        # ì»¤ìŠ¤í…€ íŒŒì´í”„ë¼ì¸ í´ë˜ìŠ¤ ìƒì„±
        return custom_code
```

### MLOpsì™€ í†µí•©

MLflowì™€ ê²°í•©í•˜ì—¬ ì‹¤í—˜ ì¶”ì :

```python
from python.ml.mlops.mlflow_tracker import MLflowTracker
from ml_pipeline import MLPipeline

tracker = MLflowTracker(experiment_name='my_experiment')

with tracker.start_run():
    pipeline = MLPipeline()
    pipeline.fit(X_train, y_train)

    # ë©”íŠ¸ë¦­ ë¡œê¹…
    tracker.log_metrics({'accuracy': 0.95})

    # ëª¨ë¸ ë¡œê¹…
    tracker.log_model(pipeline.model, 'model')
```

### ë°°í¬

ìƒì„±ëœ íŒŒì´í”„ë¼ì¸ ë°°í¬:

```python
from python.ml.deployment.model_server import ModelServer

# íŒŒì´í”„ë¼ì¸ ì €ì¥
pipeline.save('models/pipeline.pkl')

# APIë¥¼ í†µí•´ ì„œë¹™
server = ModelServer()
server.register_model('my_pipeline', 'models/pipeline.pkl', 'classifier')
server.start()
```

---

## ğŸ› ë¬¸ì œ í•´ê²°

### ë¬¸ì œ: Import ëˆ„ë½
**í•´ê²°ì±…**: ë…¸íŠ¸ë¶ì˜ ì²« ë²ˆì§¸ ì…€ì— í•„ìš”í•œ import ì¶”ê°€

### ë¬¸ì œ: ë³µì¡í•œ ì „ì²˜ë¦¬ê°€ ì¶”ì¶œë˜ì§€ ì•ŠìŒ
**í•´ê²°ì±…**: ë…¸íŠ¸ë¶ì—ì„œ ì „ì²˜ë¦¬ë¥¼ í•¨ìˆ˜ë¡œ ë¦¬íŒ©í† ë§

### ë¬¸ì œ: í”„ë ˆì„ì›Œí¬ê°€ ê°ì§€ë˜ì§€ ì•ŠìŒ
**í•´ê²°ì±…**: í”„ë ˆì„ì›Œí¬ë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì§€ì •:
```python
transformer = NotebookToPipeline('notebook.ipynb', framework='sklearn')
```

### ë¬¸ì œ: ìƒì„±ëœ ì½”ë“œê°€ ì‹¤í–‰ë˜ì§€ ì•ŠìŒ
**í•´ê²°ì±…**:
1. ìƒì„±ëœ ì½”ë“œ ê²€í† 
2. ëª¨ë“  ì¢…ì†ì„±ì´ ë‚˜ì—´ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
3. ë¨¼ì € ìƒ˜í”Œ ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸
4. í•„ìš”ì— ë”°ë¼ ìƒì„±ëœ ì½”ë“œ ìˆ˜ì •

---

## ğŸ“š ì˜ˆì œ

`examples/notebook_to_pipeline/`ì—ì„œ ì™„ì „í•œ ì˜ˆì œë¥¼ ì°¸ì¡°í•˜ì„¸ìš”:
- `example_sklearn.ipynb` - scikit-learn ë¶„ë¥˜
- `example_pytorch.ipynb` - PyTorch ë”¥ëŸ¬ë‹
- `example_timeseries.ipynb` - ì‹œê³„ì—´ ì˜ˆì¸¡
- `example_nlp.ipynb` - NLP íŒŒì´í”„ë¼ì¸

---

## ğŸš€ ë‹¤ìŒ ë‹¨ê³„

íŒŒì´í”„ë¼ì¸ì„ ìƒì„±í•œ í›„:

1. **ê²€í† **: ìƒì„±ëœ ì½”ë“œ ê²€í† 
2. **í…ŒìŠ¤íŠ¸**: ìƒ˜í”Œ ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸
3. **ì»¤ìŠ¤í„°ë§ˆì´ì¦ˆ**: í•„ìš”ì— ë”°ë¼ ì„¤ì • ì¡°ì •
4. **í†µí•©**: MLOps ë„êµ¬ì™€ í†µí•© (MLflow, ëª¨ë¸ ì„œë¹™)
5. **ë°°í¬**: í”„ë¡œë•ì…˜ì— ë°°í¬

---

## ğŸ”„ ì „ì²´ ì›Œí¬í”Œë¡œìš° ì˜ˆì œ

```python
# 1ë‹¨ê³„: ë…¸íŠ¸ë¶ ë³€í™˜
from python.ml.pipeline.notebook_to_pipeline import NotebookToPipeline

transformer = NotebookToPipeline('customer_churn.ipynb')
transformer.parse_notebook()
files = transformer.generate_pipeline(
    output_path='churn_pipeline.py',
    include_tests=True,
    include_config=True
)

# 2ë‹¨ê³„: ìƒì„±ëœ íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ í•™ìŠµ
from churn_pipeline import MLPipeline
import pandas as pd

X_train = pd.read_csv('data/train.csv')
y_train = X_train['churn']
X_train = X_train.drop('churn', axis=1)

pipeline = MLPipeline()
pipeline.fit(X_train, y_train)
pipeline.save('models/churn_model.pkl')

# 3ë‹¨ê³„: MLflowë¡œ ì¶”ì 
from python.ml.mlops.mlflow_tracker import MLflowTracker

tracker = MLflowTracker(experiment_name='churn_prediction')
with tracker.start_run():
    tracker.log_params({'model_type': 'RandomForest'})
    tracker.log_metrics({'accuracy': 0.92})
    tracker.log_model(pipeline.model, 'churn_model')

# 4ë‹¨ê³„: í”„ë¡œë•ì…˜ì— ë°°í¬
from python.ml.deployment.model_server import ModelServer

server = ModelServer(port=8000)
server.register_model(
    model_name='churn_predictor',
    model_path='models/churn_model.pkl',
    model_type='classifier'
)
server.start()

# 5ë‹¨ê³„: ëª¨ë‹ˆí„°ë§ ì„¤ì •
from python.ml.mlops.model_monitor import ModelMonitor

monitor = ModelMonitor(
    model_name='churn_predictor',
    monitoring_window=10000,
    drift_threshold=0.1
)

# í”„ë¡œë•ì…˜ì—ì„œ ì˜ˆì¸¡ ë¡œê¹…
for customer in production_data:
    prediction = pipeline.predict([customer])
    monitor.log_prediction(
        input_data=customer,
        prediction=prediction,
        latency_ms=25
    )

# ë“œë¦¬í”„íŠ¸ í™•ì¸
drift_report = monitor.check_drift(X_train, production_data)
if drift_report['drift_detected']:
    print("âš ï¸ ë°ì´í„° ë“œë¦¬í”„íŠ¸ ê°ì§€! ì¬í•™ìŠµ í•„ìš”")
```

---

## ğŸ“– ê´€ë ¨ ë¬¸ì„œ

- **PHASE_10_USAGE_GUIDE_KR.md**: MLOps ë„êµ¬ ì‚¬ìš© ê°€ì´ë“œ
- **SYSTEM_OVERVIEW_KR.md**: ì „ì²´ ì‹œìŠ¤í…œ ê°œìš”
- **API_REFERENCE_KR.md**: API ë ˆí¼ëŸ°ìŠ¤
- **TECHNICAL_SUMMARY_KR.md**: ê¸°ìˆ  ìš”ì•½

---

*ì‘ì„±ì¼: 2025ë…„ 10ì›” 1ì¼*
*ë²„ì „: 1.0.0*
*ML MCP System v2.0.0ì˜ ì¼ë¶€*
